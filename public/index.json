[
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/1-setup-infrastructure/",
	"title": "1. Setup &amp; Infrastructure Deployment",
	"tags": [],
	"description": "",
	"content": "Setup \u0026amp; Infrastructure Deployment üöÄ Complete guide for setting up AWS infrastructure for DynamoDB Advanced Patterns workshop\nThis module provides the foundational setup required for the DynamoDB Advanced Patterns workshop, ensuring all participants have a working environment using AWS Free Tier.\nüìã Learning Objectives By the end of this module, you will:  ‚úÖ Verify AWS account and Free Tier eligibility ‚úÖ Navigate AWS Console efficiently ‚úÖ Deploy infrastructure via CloudFormation ‚úÖ Verify all resources created successfully ‚úÖ Setup monitoring and billing alerts  üèóÔ∏è Architecture Overview We\u0026rsquo;ll deploy infrastructure across two AWS regions: üéØ What We\u0026rsquo;ll Build We\u0026rsquo;re building a simplified e-commerce platform with:  Users: Customer profiles and authentication Products: Catalog with categories and pricing Orders: Shopping cart and order management Real-time processing: Stream-based updates Global availability: Multi-region deployment  üì¶ Resources Created This CloudFormation template will create:  DynamoDB Table: Global table with streams enabled Lambda Function: Stream processor for real-time updates IAM Roles: Secure access policies CloudWatch Dashboard: Monitoring and metrics Billing Alerts: Cost protection mechanisms  üöÄ Prerequisites Before starting, ensure you have:  AWS Account with Free Tier eligibility Administrative access to AWS Console Basic understanding of AWS services Modern web browser (Chrome, Firefox, Safari)  Let\u0026rsquo;s begin with the infrastructure setup that will support our multi-region DynamoDB implementation.  You can choose Personal or Business account  Add payment method  Enter your credit card information and select Verify and Add.  Note: You can choose a different address for your account by selecting Use a new address before Verify and Add.    Verify your phone number  Enter the phone number. Enter the security check code then select Call me now. AWS will contact and verify account opening.  Select Support Plan  In the Select a support plan page, select an effective plan, to compare plans, see Compare AWS Support Plans.  Wait for your account to be activated  After selecting Support plan, the account is usually activated after a few minutes, but the process can take up to 24 hours. You will still be able to log in to your AWS account at this time, the AWS Home page may show a ‚ÄúComplete Sign Up‚Äù button during this time, even if you have completed all the steps in the registration section. After receiving an email confirming your account has been activated, you can access all AWS services.  Important  The following AWS Identity and Access Management (IAM) actions will reach the end of standard support on July 2023: aws-portal:ModifyAccount and aws-portal:ViewAccount. See the Using fine-grained AWS Billing actions to replace these actions with fine-grained actions so you have access to AWS Billing, AWS Cost Management, and AWS accounts consoles. If you created your AWS account or AWS Organizations Management account before March 6, 2023, the fine-grained actions will be effective starting July 2023. We recommend you to add the fine-grained actions, but not remove your existing permissions with aws-portal or purchase-orders prefixes. If you created your AWS account or AWS Organizations Management account on or after March 6, 2023, the fine-grained actions are effective immediately. AWS assigns the following unique identifiers to each AWS account: AWS account ID: A 12-digit number, such as 012345678901, that uniquely identifies an AWS account. Many AWS resources include the account ID in their Amazon Resource Names (ARNs). The account ID portion distinguishes resources in one account from the resources in another account. If you\u0026rsquo;re an AWS Identity and Access Management (IAM) user, you can sign in to the AWS Management Console using either the account ID or account alias. While account IDs, like any identifying information, should be used and shared carefully, they are not considered secret, sensitive, or confidential information. Canonical user ID: An alpha-numeric identifier, such as 79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be, that is an obfuscated form of the AWS account ID. You can use this ID to identify an AWS account when granting cross-account access to buckets and objects using Amazon Simple Storage Service (Amazon S3). You can retrieve the canonical user ID for your AWS account as either the root user or an IAM user. You must be authenticated with AWS to view these identifiers.  Warning Do not provide your AWS credentials (including passwords and access keys) to a third party that needs your AWS account identifiers to share AWS resources with you. Doing so would give them the same access to the AWS account that you have.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/",
	"title": "DynamoDB Advanced Patterns Workshop",
	"tags": [],
	"description": "",
	"content": "DynamoDB Advanced Patterns Building Multi-Region Architectures with Global Tables and Streams Overview In this comprehensive workshop, you will be building a Multi-Region E-commerce Platform using DynamoDB Advanced Patterns and AWS Free Tier. You will learn Single Table Design, implement Global Tables for multi-region replication, and build real-time stream processing with Lambda. Finally, we will implement comprehensive monitoring and optimization strategies while maintaining strict cost control within Free Tier limits.\nSingle Table Design Single Table Design is a DynamoDB modeling approach where you store multiple entity types in one table using composite keys. This pattern optimizes for performance and cost by reducing the number of requests and leveraging DynamoDB\u0026rsquo;s partition-based architecture. When implemented correctly, it provides sub-millisecond query performance while minimizing capacity consumption.\nAs a best practice, design your access patterns first before creating your table structure. Single Table Design requires careful planning of partition keys (PK) and sort keys (SK) to support all your query patterns efficiently. This workshop uses a proven e-commerce data model that supports 6 optimized access patterns while staying within Free Tier limits.\n\rGlobal Tables Multi-Region Global Tables provide fully managed multi-region, multi-active database replication. Data written to any region is automatically replicated to all other regions within seconds. This enables you to build globally distributed applications with local read and write access, improving performance and providing disaster recovery capabilities.\nDynamoDB Streams \u0026amp; Lambda DynamoDB Streams capture data modification events in your table in near real-time. When combined with AWS Lambda, you can build event-driven architectures that automatically process changes, update derived data, send notifications, or trigger business workflows. This pattern is essential for building reactive, scalable applications.\nGlobal Secondary Indexes (GSI) Global Secondary Indexes allow you to query your data using different access patterns than your main table. GSIs have their own partition and sort keys, enabling efficient queries across different dimensions of your data. Proper GSI design is crucial for performance optimization and cost control.\nMonitoring \u0026amp; Cost Optimization CloudWatch monitoring provides real-time visibility into your DynamoDB performance, capacity utilization, and costs. Combined with billing alerts and Free Tier tracking, you can ensure optimal performance while maintaining strict cost control. This workshop implements comprehensive monitoring dashboards and automated alerting.\nMain Content  Setup \u0026amp; Infrastructure Deployment Single Table Design Implementation Global Tables Multi-Region Setup DynamoDB Streams \u0026amp; Lambda Processing Monitoring \u0026amp; Performance Optimization Advanced Patterns Cleanup \u0026amp; Resource Management  "
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/2-single-table-design/",
	"title": "2. Single Table Design Implementation",
	"tags": [],
	"description": "",
	"content": "Single Table Design Implementation üìä Learn how to implement DynamoDB Single Table Design patterns for optimal performance and cost efficiency\nOverview  Single Table Design is a revolutionary approach to data modeling in DynamoDB. Instead of using multiple tables like in relational databases, we store all entity types (Users, Products, Orders) in one table using composite keys for relationships.  Why Single Table Design? Traditional Relational Approach Problems:  Multiple tables = Multiple queries = Higher latency JOINs are expensive and not available in DynamoDB Inconsistent performance across different query patterns Higher costs from managing multiple tables  DynamoDB Single Table Benefits:  Single query retrieves related data Consistent performance across all access patterns Lower costs with fewer tables and operations Atomic transactions across entity types  Learning Objectives By the end of this module, you will:  ‚úÖ Understand Single Table Design principles and benefits ‚úÖ Design composite keys (PK + SK) for multiple entity types ‚úÖ Create and query data using DynamoDB Console ‚úÖ Implement Global Secondary Indexes (GSI) for flexible access patterns ‚úÖ Analyze performance metrics and costs  Module Duration: 90 minutes  Theory: 20 minutes - Core concepts and principles Demo: 25 minutes - Console navigation and data creation Hands-on: 35 minutes - Create your own e-commerce data Review: 10 minutes - Performance analysis and Q\u0026amp;A  E-commerce Data Model Overview We\u0026rsquo;ll build a simplified e-commerce platform with these entities:    PK SK Entity Data     USER#user1 PROFILE User name, email, phone   USER#user1 ORDER#ord1 Order status, total, date   PRODUCT#p1 DETAILS Product name, price, category   ORDER#ord1 ITEM#p1 OrderItem quantity, price, product    Access Patterns We\u0026rsquo;ll Implement    Pattern Description Query Method     1 Get user profile PK = USER#id, SK = PROFILE   2 Get user\u0026rsquo;s orders PK = USER#id, SK begins_with ORDER#   3 Get order details with items PK = ORDER#id   4 Get products by category GSI1: CATEGORY# queries   5 Get products by price range GSI2: PRICE# queries   6 Get orders by status GSI2: STATUS# queries    Key Concepts Composite Keys Strategy  Partition Key (PK): Groups related items together Sort Key (SK): Enables range queries and relationships GSI Keys: Enable additional query patterns  Entity Namespacing  USER#: All user-related data PRODUCT#: All product-related data ORDER#: All order-related data CATEGORY#: Product groupings STATUS#: Order status groupings  Design Philosophy: In Single Table Design, we model our table structure based on HOW we\u0026rsquo;ll query the data, not how we\u0026rsquo;ll store it. This is the opposite of relational database design!\n\rWhat You\u0026rsquo;ll Build By the end of this module, you\u0026rsquo;ll have created:  User profiles with proper key structure Product catalog with category and price indexing Order management with item relationships Efficient queries using table and GSI patterns Performance insights from CloudWatch metrics  Cost Safety: All exercises use minimal data and stay well within AWS Free Tier limits. Monitor the CloudWatch dashboard to track usage.\n\rPrerequisites Before starting this module, ensure you have:  Completed Module 1: Infrastructure Setup DynamoDB table demo-ecommerce-freetier is Active Access to AWS Console with DynamoDB permissions Basic understanding of NoSQL concepts  Ready to revolutionize your data modeling approach? Let\u0026rsquo;s dive into Single Table Design!\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/3-global-tables-setup/",
	"title": "3. Global Tables Multi-Region Setup",
	"tags": [],
	"description": "",
	"content": "Global Tables Multi-Region Setup üåç Set up multi-region DynamoDB for worldwide access\nOverview Global Tables transforms your single-region DynamoDB table into a globally distributed database that serves users worldwide with low latency.\nWhy Global Tables? The Problem  High Latency: Users far from database experience slow response No Disaster Recovery: Single point of failure Limited Scale: All traffic through one region  The Solution Before: US-EAST-1 only ‚Üí High latency for EU users After: US-EAST-1 + EU-WEST-1 ‚Üí Low latency globally What You\u0026rsquo;ll Learn  Verify Global Setup: Check multi-region configuration Test Replication: Write in one region, read in another Multi-Region Operations: Handle global data scenarios  Key Benefits  Sub-10ms latency for users worldwide Automatic replication between regions (0.5-2 seconds) Free Tier friendly: Applies per region Built-in disaster recovery  Global Tables Basics Replication Flow 1. Write to US-EAST-1 ‚Üí ORDER#12345 created 2. DynamoDB Streams captures change 3. Auto-replication to EU-WEST-1 4. ORDER#12345 available in Europe (1-2 seconds) Key Features  Bi-directional: Read/write from any region Eventually Consistent: Changes sync within seconds Conflict Resolution: Last Writer Wins Zero downtime: Regional failover automatic  Module Contents  Global Tables Overview - Understand the architecture Verify Global Setup - Check your configuration Multi-Region Operations - Test cross-region functionality  Setup: Your CloudFormation deployment already configured Global Tables between US-East-1 and EU-West-1.\n\r\r3.1 Global Tables Overview\r\r\r3.2 Verify Global Setup\r\r\r3.3 Multi-Region Operations\r\r\rLet\u0026rsquo;s make your DynamoDB table globally accessible!\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/4-streams-lambda-processing/",
	"title": "4. Streams &amp; Lambda Processing",
	"tags": [],
	"description": "",
	"content": "DynamoDB Streams \u0026amp; Lambda Processing ‚ö° Set up real-time event processing for your DynamoDB table\nModule Overview Learn how to capture and process data changes in real-time using DynamoDB Streams and AWS Lambda.\nWhat You\u0026rsquo;ll Learn  Enable Streams: Turn on change tracking for your table Create Lambda: Build a function to process events Test Processing: See events trigger in real-time  Simple Architecture Key Benefits  Real-time: Process changes instantly Automatic: No polling required Scalable: Lambda handles concurrency Cost-effective: Pay only for usage  Module Contents  Stream Configuration - Enable streams on your table Lambda Function Setup - Create and connect Lambda  Free Tier: Lambda provides 1 million free requests per month. This demo uses minimal resources.\n\r\r4.1 Stream Configuration\r\r\r4.2 Lambda Function Setup\r\r\rLet\u0026rsquo;s add real-time processing to your DynamoDB table. Real-time Processing\n Process data changes within 100-500 milliseconds No polling required - events pushed automatically Scale to millions of events per second  Event-Driven Architecture\n Decouple data storage from business logic Trigger multiple downstream systems Build reactive, responsive applications  Cost Effective\n Pay only for actual processing time AWS Free Tier includes 1M Lambda invocations No infrastructure to manage  Common Use Cases    Pattern Trigger Action     Audit Trail Any change Log to S3/CloudWatch   Cache Invalidation Item update Clear Redis/ElastiCache   Notifications Order created Send email/SMS   Analytics User activity Update metrics dashboard   Search Index Product change Update Elasticsearch   Workflow Status change Trigger Step Functions    Stream Processing Patterns Fan-out Pattern: One change triggers multiple Lambda functions\nDynamoDB Change ‚Üí Stream ‚Üí Lambda 1 (Email)\r‚Üí Lambda 2 (Analytics) ‚Üí Lambda 3 (Cache Update)\rPipeline Pattern: Sequential processing through multiple stages\nOrder Created ‚Üí Validate ‚Üí Process Payment ‚Üí Update Inventory ‚Üí Ship\rAggregation Pattern: Combine multiple changes into summaries\nSales Records ‚Üí Real-time Revenue Dashboard\rUser Actions ‚Üí Activity Analytics\rPerformance Characteristics  Latency: Typically 100-500ms from change to processing Throughput: Scales automatically with your data volume Reliability: Automatic retries and error handling Ordering: Changes processed in order per item Retention: Stream records available for 24 hours  Module Structure This module is organized into hands-on sections that build upon each other:  Stream Configuration - Enable and configure DynamoDB Streams Lambda Function Setup - Create and deploy stream processing functions Event Processing Practice - Test with real data changes Monitoring \u0026amp; Debugging - Track performance and troubleshoot issues  Each section includes:  ‚úÖ Step-by-step AWS Console instructions ‚úÖ Code examples and templates ‚úÖ Screenshot placeholders for documentation ‚úÖ Troubleshooting guides ‚úÖ Real-world scenarios  Prerequisites Before starting this module, ensure you have:  ‚úÖ Completed Module 1 (DynamoDB table setup) ‚úÖ Basic understanding of AWS Lambda ‚úÖ Familiarity with JSON and event-driven concepts ‚úÖ AWS Console access with appropriate permissions  Learning Objectives By the end of this module, you will:  Understand DynamoDB Streams architecture and event flow Configure Lambda functions to process stream events Implement common event-driven patterns Monitor stream processing performance Debug stream processing issues Design scalable event-driven applications  "
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/5-monitoring-optimization/",
	"title": "5. Monitoring &amp; Optimization",
	"tags": [],
	"description": "",
	"content": "Monitoring \u0026amp; Optimization üìà Essential monitoring and cost optimization for your DynamoDB workshop\nModule Overview Learn how to monitor your DynamoDB table and stay within Free Tier limits with practical CloudWatch dashboards and cost tracking.\nWhat You\u0026rsquo;ll Learn  CloudWatch Dashboard: Create a monitoring view for your table Cost Tracking: Monitor Free Tier usage to avoid charges Basic Alerts: Set up simple alarms for capacity limits  Key Metrics to Monitor    Metric Free Tier Limit What to Watch     Read Capacity 25 RCU Keep usage under 20 RCU   Write Capacity 25 WCU Keep usage under 20 WCU   Storage 25 GB Monitor data growth    Free Tier Monitoring Stay within limits with these simple checks:\n‚úÖ Dashboard shows green metrics\r‚úÖ Storage under 20 GB\r‚úÖ RCU/WCU usage under 80%\r‚úÖ Billing dashboard shows $0.00\rModule Contents  CloudWatch Dashboards - Create monitoring views Cost Analysis - Track Free Tier usage  Focus: This module covers only essential monitoring needed for the workshop. Advanced patterns are covered separately.\n\r\r5.1 CloudWatch Basic Monitoring\r\r\r5.2 Cost Analysis \u0026amp; Optimization\r\r\rLet\u0026rsquo;s set up basic monitoring to keep your workshop running smoothly and cost-free.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/6-advanced-patterns/",
	"title": "6. Advanced Patterns",
	"tags": [],
	"description": "",
	"content": "Advanced DynamoDB Patterns üöÄ Learn key DynamoDB techniques for better performance\nModule Overview Master essential DynamoDB patterns that improve performance and prevent common issues in your applications.\nWhat You\u0026rsquo;ll Learn  Batch Operations: Process multiple items efficiently Conditional Updates: Prevent data conflicts and race conditions  Key Benefits  Better Performance: Reduce API calls and latency Data Safety: Prevent overselling and data corruption Free Tier Friendly: Maximize value within limits  Core Patterns 1. Batch Operations Process multiple items in single API calls: ‚ùå Single: 100 separate API calls ‚úÖ Batch: 4 API calls (25 items each) 2. Conditional Updates Prevent race conditions: ‚ùå Without conditions: Two users buy last item ‚úÖ With conditions: Only first user succeeds Module Contents  Batch Operations - Efficient multi-item processing Conditional Updates - Safe data modifications  Focus: These patterns are essential for any production DynamoDB application.\n\r\r6.1 Batch Operations\r\r\r6.2 Conditional Updates\r\r\rLet\u0026rsquo;s implement advanced patterns for better DynamoDB applications.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/7-cleanup-resources/",
	"title": "7. Cleanup Resources",
	"tags": [],
	"description": "",
	"content": "Resource Cleanup In this section, you will learn how to clean up resources on AWS Cloud to prevent incurring unnecessary costs.\nWhy Cleanup is Important  Cost Control: Prevent unexpected AWS charges Resource Management: Remove unused infrastructure Best Practices: Learn proper resource lifecycle management  1. Delete the DynamoDB Table Created in the Lab  Access the DynamoDB Management Console On the left navigation bar, select Tables Select the DynamoDB table demo-ecommerce-freetier related to the lab Click on Actions Choose Delete table Type the table name to confirm Confirm by clicking Delete  2. Delete CloudWatch Resources Created in the Lab  Access the CloudWatch Management Console On the left navigation bar, go to Dashboards Select all dashboards related to the lab Click on Actions Choose Delete dashboards Confirm deletion by clicking Delete On the left navigation bar, go to Alarms Select all alarms related to the lab Click on Actions Choose Delete Confirm deletion by clicking Delete  3. Delete Lambda Functions (if created)  Access the Lambda Management Console On the left navigation bar, navigate to Functions Select the Lambda functions related to the lab Click on Actions Choose Delete function Confirm by clicking Delete  4. Delete SNS Topics (if created)  Access the SNS Management Console On the left navigation bar, select Topics Select all SNS topics related to the lab Click on Actions Choose Delete Type \u0026ldquo;delete me\u0026rdquo; to confirm Confirm deletion by clicking Delete  5. Verify Billing and Costs  Access the Billing and Cost Management Console Check the current month charges Verify that all charges show $0.00 Confirm no unexpected services are running  Final Verification ‚úÖ Cleanup Checklist:\n DynamoDB table deleted CloudWatch dashboards and alarms removed Lambda functions deleted (if any) SNS topics deleted (if any) Billing shows $0.00 charges   Congratulations! You have successfully completed the DynamoDB Advanced Patterns workshop and cleaned up all resources.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/1-setup-infrastructure/1.1-aws-freetier-overview/",
	"title": "1.1 AWS Free Tier Overview",
	"tags": [],
	"description": "",
	"content": "AWS Free Tier Overview üÜì Understanding AWS Free Tier limits and ensuring zero-cost workshop experience\nWhat is AWS Free Tier? AWS Free Tier provides new customers access to AWS services at no charge for a limited time. It includes three types of offerings:\n1. 12 Months Free Available for 12 months following your AWS sign-up date:\n Amazon DynamoDB: 25 GB storage, 25 WCU, 25 RCU AWS Lambda: 1 million requests per month Amazon CloudWatch: 10 metrics, 10 alarms, 1 million API requests  2. Always Free Available to all AWS customers indefinitely:\n DynamoDB: 25 GB storage (always free) Lambda: 1 million requests, 400,000 GB-seconds compute time CloudWatch: 10 custom metrics and 10 alarms  3. Trials Short-term free access to certain services\nFree Tier Limits for This Workshop    Service Free Tier Our Usage Safety %     DynamoDB RCU 25 units 15 units 60%   DynamoDB WCU 25 units 15 units 60%   DynamoDB Storage 25 GB \u0026lt;1 GB 4%   Lambda Requests 1M/month ~100/day 0.3%   Lambda Duration 400K GB-sec \u0026lt;1K GB-sec 0.25%   CloudWatch 10 metrics 6 metrics 60%   Data Transfer 1 GB \u0026lt;100 MB 10%    Overall Free Tier Usage: ~50% = 100% SAFE! üõ°Ô∏è\nCost Protection: We\u0026rsquo;re using only 50% of available Free Tier limits, ensuring zero charges throughout the workshop.\n\rRegional Considerations Primary Region: US East (N. Virginia)  Why chosen: Highest Free Tier allowances DynamoDB: Full 25 RCU/WCU available Lambda: Full 1M requests available Best for: Primary workloads and testing  Secondary Region: EU West (Ireland)  Purpose: Global Tables replication Free Tier: Same limits as primary region Usage: Minimal (replica table only) Cost impact: Near zero  Monitoring Free Tier Usage AWS Billing Dashboard  Navigate to: AWS Console ‚Üí Billing \u0026amp; Cost Management Free Tier usage: Track current consumption Alerts: Set up when approaching 80% of limits Forecasting: Predict monthly usage  CloudWatch Billing Alarms Automatic alerts when:\n DynamoDB consumed units \u0026gt; 20 (80% of limit) Lambda invocations \u0026gt; 800K/month (80% of limit) Overall estimated charges \u0026gt; $1.00  Free Tier Best Practices 1. Monitor Regularly  Check Free Tier dashboard daily during workshop Set up billing alerts before deployment Monitor resource utilization in CloudWatch  2. Use Appropriate Capacity DynamoDB Provisioned Capacity: - Read Capacity Units (RCU): 5 (well under 25 limit) - Write Capacity Units (WCU): 5 (well under 25 limit) - On-Demand: NOT recommended (can exceed Free Tier) 3. Clean Up Resources  Delete test data regularly Remove unused Lambda functions Clean up CloudWatch logs older than 7 days  Common Free Tier Pitfalls to Avoid Avoid These Mistakes: 1. On-Demand DynamoDB: Can quickly exceed Free Tier 2. Multiple Regions: Deploying same resources in \u0026gt;2 regions 3. Large Data Sets: Uploading \u0026gt;25GB to DynamoDB 4. Forgot Cleanup: Leaving resources running beyond workshop\n\rMistake #1: Provisioned vs On-Demand ‚ùå WRONG: DynamoDB On-Demand - Pay per request (can be expensive) - Unpredictable costs - No Free Tier protection ‚úÖ CORRECT: DynamoDB Provisioned - Fixed capacity units - Predictable costs - Protected by Free Tier limits Mistake #2: Resource Multiplication ‚ùå WRONG: Deploy to 5 regions - 5x resource consumption - 5x Free Tier usage - Likely to exceed limits ‚úÖ CORRECT: Deploy to 2 regions max - Minimal resource usage - Well within Free Tier - Global availability maintained Emergency Procedures If You See Charges Appearing  STOP IMMEDIATELY: Pause all workshop activities Check Billing Dashboard: Identify source of charges Review Resources: List all active resources Contact Support: Use AWS Free Tier support if needed Delete Resources: Remove anything outside workshop scope  Quick Resource Audit Commands # List all DynamoDB tables aws dynamodb list-tables --region us-east-1 # List all Lambda functions  aws lambda list-functions --region us-east-1 # Check CloudFormation stacks aws cloudformation list-stacks --region us-east-1 Pre-Workshop Checklist Before starting the infrastructure deployment:\n AWS account created and verified Free Tier eligibility confirmed (account \u0026lt;12 months old) Billing alerts configured Free Tier dashboard bookmarked Emergency contact information ready Understanding of resource limits confirmed  Ready to Continue: Once you\u0026rsquo;ve reviewed the Free Tier limits and understand the safety measures, proceed to the Architecture Overview to understand what we\u0026rsquo;ll be building.\n\r"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/1-setup-infrastructure/1.2-architecture-overview/",
	"title": "1.2 Architecture Overview",
	"tags": [],
	"description": "",
	"content": "Architecture Overview üèóÔ∏è Understanding the complete infrastructure we\u0026rsquo;ll deploy for the DynamoDB workshop\nHigh-Level Architecture Our workshop infrastructure spans two AWS regions to demonstrate Global Tables functionality while maintaining Free Tier compliance.\nCore Components 1. DynamoDB Global Table Primary Table (US-East-1):\n Table Name: demo-ecommerce-freetier Partition Key: PK (String) Sort Key: SK (String) Capacity: 5 RCU / 5 WCU (Provisioned) Streams: Enabled (NEW_AND_OLD_IMAGES) Point-in-time Recovery: Enabled  Replica Table (EU-West-1):\n Synchronized: Automatic replication Read Capacity: 5 RCU Eventual Consistency: Cross-region Local Reads: Low latency for EU users  2. Lambda Stream Processor Function Configuration:\nRuntime: Python 3.9 Memory: 128 MB (Free Tier optimized) Timeout: 30 seconds Environment: Demo Trigger: DynamoDB Streams Processing Logic:\n Stream Records: Process INSERT, MODIFY, REMOVE events Data Validation: Ensure data integrity Audit Logging: Track all changes Error Handling: Dead letter queue for failed records  3. CloudWatch Monitoring Dashboard Components:\n DynamoDB Metrics: Read/Write capacity utilization Lambda Metrics: Invocation count, duration, errors Cost Tracking: Real-time Free Tier usage Performance: Latency and throughput metrics  Billing Alarms:\n Alert at $1.00: Early warning system Alert at 80% Free Tier: Usage monitoring Email Notifications: Immediate awareness  Data Model Architecture Single Table Design Pattern Our e-commerce platform uses a single DynamoDB table with multiple entity types:\n   Entity Type Partition Key Sort Key Purpose     User Profile USER#id PROFILE User metadata   User Addresses USER#id ADDRESS#id Shipping info   Product PRODUCT#id DETAILS Product catalog   Product Reviews PRODUCT#id REVIEW#user_id Customer reviews   Order Header ORDER#id DETAILS Order metadata   Order Items ORDER#id ITEM#product_id Order contents   Category CATEGORY#id DETAILS Product groups    Access Patterns  Get User Profile: PK=USER#123, SK=PROFILE Get User\u0026rsquo;s Orders: PK=USER#123, SK begins_with ORDER# Get Product Details: PK=PRODUCT#456, SK=DETAILS Get Order with Items: PK=ORDER#789, SK begins_with ITEM# Get Product Reviews: PK=PRODUCT#456, SK begins_with REVIEW#  Security Architecture IAM Roles and Policies Lambda Execution Role:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:*:*:table/demo-ecommerce-freetier/stream/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; } ] } Principle of Least Privilege:\n Lambda: Only stream read permissions CloudWatch: Only metrics and logs write DynamoDB: Table-specific access only  Network Architecture Regional Deployment Strategy Primary Region (US-East-1):\n Availability: 99.99% SLA Latency: \u0026lt;10ms for US users Capacity: Full read/write operations Backup: Point-in-time recovery  Secondary Region (EU-West-1):\n Availability: 99.99% SLA (independent) Latency: \u0026lt;10ms for EU users Capacity: Read optimized Sync: Eventually consistent replication  Data Flow  Write Operations: Always to primary region Read Operations: Can be from either region Replication: Automatic cross-region sync Conflict Resolution: Last-writer-wins Failover: Manual promotion if needed  Cost Architecture Free Tier Optimization DynamoDB Costs:\nPrimary Table (US-East-1): - Provisioned RCU: 5 units (Free: 25) = $0.00 - Provisioned WCU: 5 units (Free: 25) = $0.00 - Storage: \u0026lt;1 GB (Free: 25 GB) = $0.00 Replica Table (EU-West-1): - Provisioned RCU: 5 units (Free: 25) = $0.00 - Cross-region replication: \u0026lt;1 GB/month = $0.00 Lambda Costs:\nStream Processor: - Invocations: ~100/day (Free: 1M/month) = $0.00 - Duration: 128MB √ó 1s √ó 100 = \u0026lt;1 GB-second = $0.00 Total Workshop Cost: $0.00 ‚úÖ\nScalability Considerations Horizontal Scaling DynamoDB:\n Auto Scaling: Can enable if needed On-Demand: Switch from provisioned Global Secondary Indexes: Add for new access patterns  Lambda:\n Concurrent Executions: Up to 1000 default Dead Letter Queue: Handle failures Reserved Concurrency: Control scaling  Performance Optimization Read Performance:\n Consistent Reads: When data consistency required Eventually Consistent: For better performance DAX: DynamoDB Accelerator for caching  Write Performance:\n Batch Operations: Reduce API calls Parallel Writes: Multiple partition keys Write Sharding: Distribute hot partitions  Monitoring and Observability Key Metrics to Monitor DynamoDB:\n Consumed Read Capacity: Target \u0026lt;80% of provisioned Consumed Write Capacity: Target \u0026lt;80% of provisioned Throttled Requests: Should be 0 Error Rate: Target \u0026lt;1%  Lambda:\n Invocation Count: Track processing volume Duration: Monitor performance trends Error Rate: Target \u0026lt;1% Dead Letter Queue: Monitor failed records  Alerting Strategy Critical Alerts:\n DynamoDB throttling events Lambda function errors Billing threshold exceeded Free Tier limit approaching  Warning Alerts:\n High capacity utilization (\u0026gt;70%) Increased error rates Performance degradation  Architecture Ready: This architecture provides a production-ready foundation for learning DynamoDB advanced patterns while staying within AWS Free Tier limits.\n\rNext Steps With the architecture understanding complete, we\u0026rsquo;ll now proceed to deploy this infrastructure using CloudFormation templates in the next section.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/1-setup-infrastructure/1.3-cloudformation-deployment/",
	"title": "1.3 CloudFormation Deployment",
	"tags": [],
	"description": "",
	"content": "CloudFormation Deployment üöÄ Step-by-step guide to deploy AWS infrastructure using Infrastructure as Code\nOverview In this section, you\u0026rsquo;ll deploy the complete DynamoDB workshop infrastructure using AWS CloudFormation. This approach ensures consistent, reproducible deployments and follows AWS best practices.\nPrerequisites Before starting deployment, ensure:\n AWS Console access with administrative permissions Verified region: US East (N. Virginia) us-east-1 Current billing status: $0.00 CloudFormation template downloaded  CloudFormation Template Overview Our template creates the following resources:Download CloudFormation Template\nCore Infrastructure  DynamoDB Table: Single table with Global Tables enabled Lambda Function: Stream processor for real-time events IAM Roles: Least privilege access policies DynamoDB Streams: Change data capture configuration  Monitoring \u0026amp; Alerting  CloudWatch Dashboard: Real-time metrics visualization CloudWatch Alarms: Threshold-based alerting Billing Alerts: Cost protection mechanisms  Security Configuration  IAM Policies: Fine-grained permissions Resource Encryption: Data protection at rest VPC Integration: Network isolation (optional)  Step-by-Step Deployment Step 1: Access CloudFormation Service   Navigate to CloudFormation\n Open AWS Management Console Search for \u0026ldquo;CloudFormation\u0026rdquo; or find it in services menu Ensure you\u0026rsquo;re in US East (N. Virginia) region    Create New Stack\n Click \u0026ldquo;Create stack\u0026rdquo; button Select \u0026ldquo;With new resources (standard)\u0026rdquo;    Step 2: Upload Template   Choose Template Source\n Select \u0026ldquo;Upload a template file\u0026rdquo; Click \u0026ldquo;Choose file\u0026rdquo; button Select the infrastructure.yaml file    Validate Template\n CloudFormation will automatically validate syntax Review template details if needed Click \u0026ldquo;Next\u0026rdquo; to proceed    Step 3: Configure Stack Parameters Stack Details:\nStack name: demo-dynamodb-freetier\rDescription: DynamoDB Advanced Patterns Workshop Infrastructure\rParameters:\nResource Configuration:\nReadCapacityUnits: 5\rWriteCapacityUnits: 5\rStreamViewType: NEW_AND_OLD_IMAGES\rStep 4: Configure Stack Options Tags (Optional):\nWorkshop: DynamoDB-Advanced-Patterns\rEnvironment: Demo\rCostCenter: Learning\rPermissions:\n Use existing service role (if available) Or allow CloudFormation to create new role  Advanced Options:\n Keep all defaults Rollback on failure: Enabled Stack creation timeout: 10 minutes  Step 5: Review and Deploy   Review Configuration\n Verify all parameters are correct Check resource list matches expectations Confirm estimated costs ($0.00 for Free Tier)    Acknowledge Capabilities\n ‚úÖ Check: \u0026ldquo;I acknowledge that AWS CloudFormation might create IAM resources\u0026rdquo; ‚úÖ Check: \u0026ldquo;I acknowledge that AWS CloudFormation might create IAM resources with custom names\u0026rdquo;    Create Stack\n Click \u0026ldquo;Create stack\u0026rdquo; button Deployment begins immediately    Monitoring Deployment Stack Events Tab Monitor real-time deployment progress:\nExpected Timeline  Total Duration: 5-7 minutes IAM Resources: 1-2 minutes DynamoDB Table: 2-3 minutes Lambda Function: 1-2 minutes CloudWatch Components: 1-2 minutes  Troubleshooting Common Issues Issue: Insufficient Permissions Symptoms: CREATE_FAILED for IAM resources Solution:\n Verify account has administrator access Check IAM permissions for CloudFormation Use root account if necessary (for workshop only)  Issue: Resource Limits Exceeded Symptoms: CREATE_FAILED for DynamoDB or Lambda Solution:\n Check Free Tier usage in billing console Verify no existing resources consuming limits Contact AWS support if needed  Issue: Region Mismatch Symptoms: Template validation errors Solution:\n Verify region is us-east-1 Check all parameters are region-appropriate Restart deployment in correct region  Verification Steps After successful deployment:\n Stack Status: CREATE_COMPLETE ‚úÖ Navigate to Outputs tab Record important values:  Table Name Lambda Function ARN Dashboard URL Stream ARN    Deployment Complete! Your DynamoDB Advanced Patterns infrastructure is now running. In the next section, we\u0026rsquo;ll verify all components are working correctly.\n\rNext Steps  Verify DynamoDB table is active Test Lambda function deployment Check CloudWatch dashboard Confirm zero billing charges Begin data modeling exercises  "
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/1-setup-infrastructure/1.4-infrastructure-verification/",
	"title": "1.4 Infrastructure Verification",
	"tags": [],
	"description": "",
	"content": "Infrastructure Verification ‚úÖ Comprehensive testing to ensure all AWS resources are properly deployed and functioning\nOverview After CloudFormation deployment, it\u0026rsquo;s critical to verify that all resources are working correctly. This section provides step-by-step verification procedures to ensure your infrastructure is ready for the workshop.\nVerification Checklist Use this checklist to systematically verify each component:\n CloudFormation stack status: CREATE_COMPLETE DynamoDB table: Active and accessible DynamoDB Global Tables: Replication configured Lambda function: Deployed and connected to stream CloudWatch dashboard: Metrics visible IAM roles: Properly configured permissions Billing status: $0.00 charges Free Tier usage: Within limits  Step 1: Verify CloudFormation Stack 1.1 Check Stack Status Navigate to CloudFormation:\n AWS Console ‚Üí CloudFormation ‚Üí Stacks Find stack: demo-dynamodb-freetier Status should be: CREATE_COMPLETE ‚úÖ  If status shows anything else:\n CREATE_IN_PROGRESS: Wait for completion CREATE_FAILED: Check Events tab for errors ROLLBACK_COMPLETE: Delete and redeploy  1.2 Review Stack Outputs Click on your stack ‚Üí Outputs tab:\nRecord these values - you\u0026rsquo;ll use them for further verification.\nStep 2: Verify DynamoDB Table 2.1 Access DynamoDB Console Navigate to DynamoDB:\n AWS Console ‚Üí Services ‚Üí DynamoDB Click Tables in left sidebar Find table: demo-ecommerce-freetier  2.2 Check Table Status Table Overview:\n   Property Expected Value     Table Status Active ‚úÖ   Partition Key PK (String)   Sort Key SK (String)   Read Capacity 5 (Provisioned)   Write Capacity 5 (Provisioned)   Point-in-time Rec. Enabled   Streams Enabled (NEW_AND_OLD_IMAGES)    2.3 Verify Table Configuration Click on table name to view details:\nGeneral Tab:\n Table name: demo-ecommerce-freetier Primary key: PK (String), SK (String) Table status: Active Creation date: Today\u0026rsquo;s date  Capacity Tab:\n Read capacity: 5 units (Provisioned) Write capacity: 5 units (Provisioned) Auto scaling: Disabled (for Free Tier safety)  2.4 Check DynamoDB Streams Exports and streams Tab:\n DynamoDB stream: Enabled ‚úÖ Stream view type: New and old images Stream ARN: Should match CloudFormation output  Step 3: Verify Global Tables Setup 3.1 Check Global Tables Configuration Global Tables Tab:\n Primary region: us-east-1 (US East N. Virginia) Replica regions: eu-west-1 (Europe Ireland) Replication status: Active  3.2 Verify Secondary Region Switch to EU-West-1:\n Change region in AWS Console to \u0026ldquo;Europe (Ireland)\u0026rdquo; Navigate to DynamoDB ‚Üí Tables Find replica table: demo-ecommerce-freetier Status should be: Active  Replica Table Properties:\n Table status: Active Read capacity: 5 units Global table: Yes (replica) Primary region: us-east-1  Step 4: Verify Lambda Function 4.1 Access Lambda Console Navigate to Lambda:\n Switch back to US-East-1 region AWS Console ‚Üí Services ‚Üí Lambda Click Functions in left sidebar Find function: demo-dynamodb-stream-processor  4.2 Check Function Configuration Function Overview:\n   Property Expected Value     Function Name demo-dynamodb-stream-processor   Runtime Python 3.9   Memory 128 MB   Timeout 30 seconds   Handler lambda_function.lambda_handler   Last Modified Today\u0026rsquo;s date    4.3 Verify Stream Trigger Configuration Tab:\n Triggers: DynamoDB stream should be listed Source: demo-ecommerce-freetier table State: Enabled Batch size: 100 (default)  4.4 Test Function Permissions Permissions Tab:\n Execution role: Should have DynamoDB stream read permissions Resource-based policy: Should be configured automatically  Step 5: Verify CloudWatch Dashboard 5.1 Access CloudWatch Console Navigate to CloudWatch:\n AWS Console ‚Üí Services ‚Üí CloudWatch Click Dashboards in left sidebar Find dashboard: demo-dynamodb-freetier-monitoring  5.2 Check Dashboard Widgets Expected Widgets:\n   Widget Description     DynamoDB RCU Read Capacity Utilization   DynamoDB WCU Write Capacity Utilization   DynamoDB Throttles Throttled Read/Write Requests   Lambda Invocations Function invocation count   Lambda Errors Function error rate   Lambda Duration Function execution duration    5.3 Verify Metrics Data Initial State (no activity yet):\n DynamoDB metrics: Should show 0 consumed capacity Lambda metrics: Should show 0 invocations All metrics: Should be visible but with no data points yet  Step 6: Verify IAM Roles and Policies 6.1 Check Lambda Execution Role Navigate to IAM:\n AWS Console ‚Üí Services ‚Üí IAM Click Roles in left sidebar Find role with name containing: demo-dynamodb-freetier  6.2 Verify Role Permissions Attached Policies:\n AWS managed policy: AWSLambdaBasicExecutionRole Inline policy: Custom DynamoDB stream permissions  Custom Policy Permissions:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-east-1:*:table/demo-ecommerce-freetier/stream/*\u0026#34; } ] } Step 7: Test Data Operations 7.1 Create Test Item Add sample data to verify table functionality:\n Go to DynamoDB Console ‚Üí Tables ‚Üí demo-ecommerce-freetier Click \u0026ldquo;Explore table items\u0026rdquo; Click \u0026ldquo;Create item\u0026rdquo;  Test Item:\n{ \u0026#34;PK\u0026#34;: \u0026#34;USER#test123\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;PROFILE\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Test User\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T10:00:00Z\u0026#34; } 7.2 Verify Item Creation Confirm item appears:\n Item should be visible in table Item count should increase to 1 No errors should appear  7.3 Check Lambda Trigger Verify stream processing:\n Go to Lambda Console Click on stream processor function Check \u0026ldquo;Monitor\u0026rdquo; tab Should see 1 invocation (from the item creation)  Step 8: Cost and Free Tier Verification 8.1 Check Current Billing Navigate to Billing:\n AWS Console ‚Üí Services ‚Üí Billing \u0026amp; Cost Management Current charges: Should show $0.00 ‚úÖ Month-to-date: Should show $0.00 ‚úÖ  8.2 Verify Free Tier Usage Free Tier Dashboard:\n DynamoDB: Should show minimal usage Lambda: Should show \u0026lt;10 invocations CloudWatch: Should show active metrics  Usage Breakdown:\n   Service Used Available % Used     DynamoDB RCU \u0026lt;1 unit 25 units \u0026lt;4%   DynamoDB WCU \u0026lt;1 unit 25 units \u0026lt;4%   DynamoDB Storage \u0026lt;0.01 GB 25 GB \u0026lt;0.1%   Lambda Requests 1 request 1M requests \u0026lt;0.001%   Lambda Duration \u0026lt;1 GB-sec 400K GB-sec \u0026lt;0.001%    Total Usage: \u0026lt;1% of Free Tier limits ‚úÖ\nStep 9: Troubleshooting Common Issues 9.1 DynamoDB Table Issues Table not found:\n Check region (must be us-east-1) Verify CloudFormation stack completed Check table name spelling  Table not Active:\n Wait 2-3 minutes for creation Check CloudFormation Events for errors Verify account limits not exceeded  9.2 Lambda Function Issues Function not found:\n Check region Verify CloudFormation outputs Check IAM permissions  No invocations after adding data:\n Verify stream is enabled on table Check trigger configuration Review function logs for errors  9.3 Permission Issues Access denied errors:\n Verify IAM role attached to Lambda Check execution role permissions Ensure resource ARNs match  9.4 Billing Issues Unexpected charges appearing:\n STOP all activities immediately Check Billing dashboard for charge sources Review resource configuration Contact AWS support if needed Consider deleting and redeploying resources  Step 10: Final Verification Summary 10.1 Complete Verification Checklist Infrastructure Status:\n CloudFormation: CREATE_COMPLETE DynamoDB: Active table with streams Global Tables: Replication working Lambda: Function deployed and triggered CloudWatch: Dashboard accessible IAM: Proper permissions configured Billing: $0.00 charges Test data: Successfully created and processed  10.2 Ready for Next Module Infrastructure Health Check:\n   Component Status Health     DynamoDB Table Active üü¢ Healthy   Global Tables Replicating üü¢ Healthy   Lambda Function Active üü¢ Healthy   CloudWatch Monitoring üü¢ Healthy   Cost Management $0.00 üü¢ On Track    Infrastructure Verification Complete: All resources are properly deployed and functioning. You\u0026rsquo;re ready to proceed to Module 2: Single Table Design.\n\rNext Steps With infrastructure successfully verified, you now have:\n Production-ready DynamoDB table with Global Tables Fully functional Lambda stream processor Complete monitoring and alerting setup Zero-cost Free Tier deployment  Ready for: Module 2: Single Table Design\nKeep This Environment: Don\u0026rsquo;t delete these resources yet - we\u0026rsquo;ll use them throughout the workshop for hands-on exercises.\n\r"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/2-single-table-design/2.1-design-principles/",
	"title": "2.1 Design Principles",
	"tags": [],
	"description": "",
	"content": "Single Table Design Principles üéØ Understanding the core concepts that make Single Table Design powerful\nThe Paradigm Shift From Relational to NoSQL Thinking Traditional relational databases organize data by entities (separate tables for Users, Products, Orders). DynamoDB organizes data by access patterns (how you\u0026rsquo;ll query the data).\nRelational Approach:\n   Table Fields     Users user_id, name, email   Products product_id, name, category   Orders order_id, user_id, status    Single Table Approach:\n   PK SK Entity Additional Data     USER#user1 PROFILE User name, email, phone   USER#user1 ORDER#ord1 Order status, total, date   PRODUCT#p1 DETAILS Product name, price, stock   ORDER#ord1 ITEM#p1 OrderItem quantity, price    Core Principles 1. Composite Primary Key Strategy Partition Key (PK) + Sort Key (SK) creates unique item identification and enables relationships:\n PK: Groups related items together (like a namespace) SK: Sorts items within a partition and creates hierarchies Together: Enable 1-to-1, 1-to-many, and many-to-many relationships  2. Entity Namespacing Use prefixes to create logical separation:\n   Entity Type PK Pattern SK Pattern Purpose     User Profile USER#user123 PROFILE Store user information   User Orders USER#user123 ORDER#order456 Link orders to users   Product Details PRODUCT#prod789 DETAILS Store product information   Order Items ORDER#order456 ITEM#prod789 Link products to orders    3. Access Pattern First Design Start with questions, then design the key structure:\n \u0026ldquo;How will I get user profile?\u0026rdquo; ‚Üí PK=USER#id, SK=PROFILE \u0026ldquo;How will I get user\u0026rsquo;s orders?\u0026rdquo; ‚Üí PK=USER#id, SK begins_with ORDER# \u0026ldquo;How will I get order details?\u0026rdquo; ‚Üí PK=ORDER#id, SK begins_with ITEM# \u0026ldquo;How will I get products by category?\u0026rdquo; ‚Üí Use GSI with CATEGORY# keys  Global Secondary Index (GSI) Strategy When to Use GSIs Use GSIs when you need to query data by attributes other than the primary key:\n Different grouping: Products by category instead of by product ID Different sorting: Orders by status instead of by user Cross-entity queries: All pending orders across all users  GSI Key Design GSI1 - Category-based queries:\n   GSI1PK GSI1SK     CATEGORY#electronics PRODUCT#prod1   CATEGORY#electronics PRODUCT#prod2   CATEGORY#books PRODUCT#prod3    GSI2 - Status/Price-based queries:\n   GSI2PK GSI2SK     STATUS#pending ORDER#order1   STATUS#shipped ORDER#order2   PRICE#100-500 PRODUCT#prod1    Benefits in Practice Performance Benefits  Single Query: Get user profile + all orders in one query Predictable Latency: Single-digit millisecond response times No JOINs: All related data retrieved together Efficient Scaling: Consistent performance at any scale  Cost Benefits  Fewer Tables: Lower DynamoDB table costs Fewer Operations: Batch queries instead of multiple calls Optimized Capacity: Better utilization of provisioned capacity Reduced Data Transfer: Less network overhead  Operational Benefits  Atomic Transactions: Update related items together Simplified Backup: One table to backup/restore Easier Monitoring: Single table metrics to track Consistent Security: One set of IAM policies  Key Design Patterns 1. Adjacency List Pattern Store related items next to each other:\nPK=USER#user1, SK=PROFILE (User details) PK=USER#user1, SK=ORDER#order1 (Order 1) PK=USER#user1, SK=ORDER#order2 (Order 2) 2. Hierarchical Data Pattern Use sort key to represent hierarchy:\nPK=ORDER#order1, SK=DETAILS (Order header) PK=ORDER#order1, SK=ITEM#prod1 (Order item 1) PK=ORDER#order1, SK=ITEM#prod2 (Order item 2) 3. GSI Overloading Pattern Use same GSI for multiple query patterns:\nGSI1PK=CATEGORY#electronics, GSI1SK=PRODUCT#prod1 GSI1PK=USER#user1@email.com, GSI1SK=PROFILE \rDesign Rule: Always start with your access patterns, then design your key structure. Don\u0026rsquo;t start with entities!\n\rCommon Anti-Patterns to Avoid ‚ùå Don\u0026rsquo;t Use Scan Operations  Wrong: Scan entire table to find items Right: Use Query with proper key structure  ‚ùå Don\u0026rsquo;t Create Too Many GSIs  Wrong: One GSI per query pattern Right: Overload GSIs for multiple patterns  ‚ùå Don\u0026rsquo;t Ignore Hot Partitions  Wrong: All items have same partition key Right: Distribute items across multiple partitions  ‚ùå Don\u0026rsquo;t Use Relational Patterns  Wrong: Normalize data across multiple items Right: Denormalize related data together  Remember: Single Table Design requires a mindset shift. Think in terms of access patterns, not entity relationships!\n\rReady for Implementation Now that you understand the principles, let\u0026rsquo;s move to the AWS Console to see these concepts in action. In the next section, we\u0026rsquo;ll navigate the DynamoDB Console and start creating our e-commerce data model.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/2-single-table-design/2.2-console-navigation/",
	"title": "2.2 Console Navigation",
	"tags": [],
	"description": "",
	"content": "DynamoDB Console Navigation üñ•Ô∏è Quick guide to navigate DynamoDB Console for Single Table Design\nAccessing Your Table Step 1: Navigate to DynamoDB Service  Open AWS Console: https://console.aws.amazon.com Verify Region: Ensure you\u0026rsquo;re in US East (N. Virginia) Access DynamoDB: Services ‚Üí Database ‚Üí DynamoDB  Step 2: Find Your Workshop Table  Click \u0026ldquo;Tables\u0026rdquo; in the left sidebar Find table: demo-ecommerce-freetier Verify Status: Should show \u0026ldquo;Active\u0026rdquo; Click table name to enter table details  Table Overview Dashboard Understanding the Table Layout When you click on your table, you\u0026rsquo;ll see several tabs:\n   Tab Purpose What You\u0026rsquo;ll Use It For     Overview Table configuration Check status, keys, capacity   Items Data management Create, view, edit items   Metrics Performance data Monitor usage and costs   Indexes GSI management View Global Secondary Indexes   Global tables Multi-region setup Check replication status    Key Information to Note Table Configuration:\n Table name: demo-ecommerce-freetier Partition key: PK (String) Sort key: SK (String) Table status: Active Item count: Currently 0 (empty table)  Items Tab - Your Data Workspace Accessing the Items View  Click \u0026ldquo;Items\u0026rdquo; tab View table structure: Currently empty Note the columns: PK, SK, and any additional attributes  This is where you\u0026rsquo;ll:\n ‚úÖ Create new items (users, products, orders) ‚úÖ View existing data ‚úÖ Edit item attributes ‚úÖ Delete items if needed  Creating Items Interface To create a new item:\n Click \u0026ldquo;Create item\u0026rdquo; button Choose input method:  Form view: Point-and-click interface JSON view: Direct JSON editing (recommended)   Switch to JSON view for easier data entry  JSON View for Data Entry Understanding JSON Format When creating items, you\u0026rsquo;ll use this JSON structure:\n{ \u0026#34;PK\u0026#34;: \u0026#34;USER#user123\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;PROFILE\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john@example.com\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T10:00:00Z\u0026#34; } Key points:\n PK and SK: Always required (your composite primary key) Additional attributes: Add as needed for each entity type Data types: Strings, numbers, booleans, lists, maps supported  Query Interface Accessing Query Functionality To query your table:\n Go to Items tab Click \u0026ldquo;Query\u0026rdquo; button (next to Create item) Choose query type:  Table query: Query main table Index query: Query GSI    Query Parameters For table queries, you\u0026rsquo;ll specify:\n Partition key (PK): Exact value (e.g., USER#user123) Sort key (SK): Optional conditions:  Exact match: PROFILE Begins with: ORDER# Between: Range queries    Global Secondary Index (GSI) Navigation Viewing GSI Configuration  Click \u0026ldquo;Indexes\u0026rdquo; tab View GSI1: Used for category-based queries View GSI2: Used for status/price-based queries  GSI Structure:\n GSI1: GSI1PK (Partition) + GSI1SK (Sort) GSI2: GSI2PK (Partition) + GSI2SK (Sort)  Metrics and Monitoring Checking Usage and Performance  Click \u0026ldquo;Metrics\u0026rdquo; tab Monitor key metrics:  Consumed read/write capacity Throttled requests (should be 0) Item count (increases as you add data)    Why this matters:\n ‚úÖ Stay within Free Tier limits ‚úÖ Monitor performance ‚úÖ Detect any issues early  Quick Actions Reference Common Console Actions    Action Location Purpose     Create Item Items tab ‚Üí Create item Add new data   Query Table Items tab ‚Üí Query Search by PK/SK   View Metrics Metrics tab Monitor performance   Check Capacity Overview tab Verify provisioned capacity    Console Tips Efficiency Tips  Use JSON view for faster item creation Copy/paste item structures for consistency Use Query, not Scan for better performance Check metrics regularly to monitor usage  Navigation Shortcuts  Tables list: DynamoDB home ‚Üí Tables Quick table access: Bookmark your table URL Region switching: Use region selector in top-right Service search: Use Ctrl+K for quick service access  Pro Tip: Keep the DynamoDB console open in a separate browser tab during the workshop for quick access between exercises.\n\rReady for Data Creation Now that you\u0026rsquo;re familiar with the console interface, you\u0026rsquo;re ready to start creating your e-commerce data model. In the next section, we\u0026rsquo;ll create users, products, and orders using the patterns you\u0026rsquo;ve learned.\nBefore Starting: Make sure you\u0026rsquo;re in the correct table (demo-ecommerce-freetier) and understand the difference between Query and Scan operations.\n\r"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/2-single-table-design/2.3-create-data-items/",
	"title": "2.3 Create Data Items",
	"tags": [],
	"description": "",
	"content": "Create Data Items üìù Step-by-step guide to create e-commerce data using Single Table Design patterns\nOverview In this section, you\u0026rsquo;ll create the core entities for our e-commerce platform: Users, Products, Orders, and Order Items. Each entity type follows specific key patterns to enable efficient querying.\nEntity Types We\u0026rsquo;ll Create    Entity PK Pattern SK Pattern Purpose     User Profile USER#userID PROFILE Store customer information   Product PRODUCT#productID DETAILS Store product catalog   Order USER#userID ORDER#orderID Link orders to customers   Order Item ORDER#orderID ITEM#productID Link products to orders    Step 1: Create User Profile Access Item Creation  Navigate to: DynamoDB ‚Üí Tables ‚Üí demo-ecommerce-freetier Click: \u0026ldquo;Items\u0026rdquo; tab Click: \u0026ldquo;Create item\u0026rdquo; button Switch to: JSON view  User Profile JSON Template Copy and paste this template, then modify with your details:\n{ \u0026#34;PK\u0026#34;: \u0026#34;USER#user001\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;PROFILE\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;USER#john.doe@email.com\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;PROFILE\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;john.doe@email.com\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;+1-555-0123\u0026#34;, \u0026#34;address\u0026#34;: { \u0026#34;street\u0026#34;: \u0026#34;123 Main St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Seattle\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;WA\u0026#34;, \u0026#34;zip\u0026#34;: \u0026#34;98101\u0026#34; }, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T10:00:00Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;active\u0026#34; } Key Patterns Explained:\n PK: USER#user001 - Groups all user data together SK: PROFILE - Identifies this as the user\u0026rsquo;s profile record GSI1PK: USER#john.doe@email.com - Enables email-based lookups GSI1SK: PROFILE - Maintains consistency in GSI  Save Your User  Review the JSON for syntax errors Click \u0026ldquo;Create item\u0026rdquo; Verify creation: Item should appear in the table view  Step 2: Create Products Electronics Product Example Create your first product - customize the values:\n{ \u0026#34;PK\u0026#34;: \u0026#34;PRODUCT#laptop001\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;DETAILS\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;CATEGORY#electronics\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;PRODUCT#laptop001\u0026#34;, \u0026#34;GSI2PK\u0026#34;: \u0026#34;PRICE#500-1000\u0026#34;, \u0026#34;GSI2SK\u0026#34;: \u0026#34;PRODUCT#laptop001\u0026#34;, \u0026#34;product_id\u0026#34;: \u0026#34;laptop001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Professional Laptop\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;High-performance laptop for professionals\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;electronics\u0026#34;, \u0026#34;price\u0026#34;: 799, \u0026#34;stock\u0026#34;: 25, \u0026#34;brand\u0026#34;: \u0026#34;TechCorp\u0026#34;, \u0026#34;specifications\u0026#34;: { \u0026#34;processor\u0026#34;: \u0026#34;Intel i7\u0026#34;, \u0026#34;memory\u0026#34;: \u0026#34;16GB RAM\u0026#34;, \u0026#34;storage\u0026#34;: \u0026#34;512GB SSD\u0026#34; }, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T10:00:00Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;active\u0026#34; } Key Patterns Explained:\n GSI1PK: CATEGORY#electronics - Enables category-based queries GSI2PK: PRICE#500-1000 - Enables price range queries Nested attributes: Store complex product details  Books Product Example Create a second product in a different category:\n{ \u0026#34;PK\u0026#34;: \u0026#34;PRODUCT#book001\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;DETAILS\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;CATEGORY#books\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;PRODUCT#book001\u0026#34;, \u0026#34;GSI2PK\u0026#34;: \u0026#34;PRICE#10-50\u0026#34;, \u0026#34;GSI2SK\u0026#34;: \u0026#34;PRODUCT#book001\u0026#34;, \u0026#34;product_id\u0026#34;: \u0026#34;book001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;DynamoDB Patterns Guide\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Complete guide to DynamoDB design patterns\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;books\u0026#34;, \u0026#34;price\u0026#34;: 29, \u0026#34;stock\u0026#34;: 100, \u0026#34;author\u0026#34;: \u0026#34;Database Expert\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-1234567890\u0026#34;, \u0026#34;pages\u0026#34;: 350, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T10:00:00Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;active\u0026#34; } Notice the differences:\n Different category: CATEGORY#books Different price range: PRICE#10-50 Book-specific attributes: author, isbn, pages  Step 3: Create Order Order Header Create an order linked to your user:\n{ \u0026#34;PK\u0026#34;: \u0026#34;USER#user001\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;ORDER#order001\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;ORDER#order001\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;DETAILS\u0026#34;, \u0026#34;GSI2PK\u0026#34;: \u0026#34;STATUS#pending\u0026#34;, \u0026#34;GSI2SK\u0026#34;: \u0026#34;ORDER#order001\u0026#34;, \u0026#34;order_id\u0026#34;: \u0026#34;order001\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user001\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;pending\u0026#34;, \u0026#34;total_amount\u0026#34;: 828, \u0026#34;tax_amount\u0026#34;: 66.24, \u0026#34;shipping_cost\u0026#34;: 0, \u0026#34;shipping_address\u0026#34;: { \u0026#34;street\u0026#34;: \u0026#34;123 Main St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Seattle\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;WA\u0026#34;, \u0026#34;zip\u0026#34;: \u0026#34;98101\u0026#34; }, \u0026#34;payment_method\u0026#34;: \u0026#34;credit_card\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T11:00:00Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2025-08-11T11:00:00Z\u0026#34; } Key Patterns Explained:\n PK: USER#user001 - Links order to user (enables \u0026ldquo;get user\u0026rsquo;s orders\u0026rdquo;) SK: ORDER#order001 - Identifies this as an order record GSI1PK: ORDER#order001 - Enables direct order lookup GSI2PK: STATUS#pending - Enables status-based queries  Step 4: Create Order Items First Order Item Add the laptop to the order:\n{ \u0026#34;PK\u0026#34;: \u0026#34;ORDER#order001\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;ITEM#laptop001\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;PRODUCT#laptop001\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;ORDER#order001\u0026#34;, \u0026#34;order_id\u0026#34;: \u0026#34;order001\u0026#34;, \u0026#34;product_id\u0026#34;: \u0026#34;laptop001\u0026#34;, \u0026#34;product_name\u0026#34;: \u0026#34;Professional Laptop\u0026#34;, \u0026#34;quantity\u0026#34;: 1, \u0026#34;unit_price\u0026#34;: 799, \u0026#34;total_price\u0026#34;: 799, \u0026#34;added_at\u0026#34;: \u0026#34;2025-08-11T11:00:00Z\u0026#34; } Second Order Item Add the book to the same order:\n{ \u0026#34;PK\u0026#34;: \u0026#34;ORDER#order001\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;ITEM#book001\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;PRODUCT#book001\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;ORDER#order001\u0026#34;, \u0026#34;order_id\u0026#34;: \u0026#34;order001\u0026#34;, \u0026#34;product_id\u0026#34;: \u0026#34;book001\u0026#34;, \u0026#34;product_name\u0026#34;: \u0026#34;DynamoDB Patterns Guide\u0026#34;, \u0026#34;quantity\u0026#34;: 1, \u0026#34;unit_price\u0026#34;: 29, \u0026#34;total_price\u0026#34;: 29, \u0026#34;added_at\u0026#34;: \u0026#34;2025-08-11T11:00:00Z\u0026#34; } Key Patterns Explained:\n PK: ORDER#order001 - Groups items with their order SK: ITEM#productID - Identifies specific items GSI1: Creates product-to-order relationship  Verify Your Data Structure Check Table Contents After creating all items, your table should contain:\n   PK SK Entity Type     USER#user001 PROFILE User Profile   USER#user001 ORDER#order001 Order (linked to user)   PRODUCT#laptop001 DETAILS Product (Electronics)   PRODUCT#book001 DETAILS Product (Books)   ORDER#order001 ITEM#laptop001 Order Item (Laptop)   ORDER#order001 ITEM#book001 Order Item (Book)    Validate Relationships Verify these relationships work:\n User ‚Üí Orders: PK=USER#user001 returns profile + orders Order ‚Üí Items: PK=ORDER#order001 returns order details + items Category grouping: GSI1 with CATEGORY#electronics returns products Status grouping: GSI2 with STATUS#pending returns orders  Data Creation Tips JSON Best Practices  Use consistent naming: Follow the established patterns Validate JSON syntax: Check for missing commas, brackets Include required attributes: PK, SK, and GSI keys Use meaningful IDs: Make them readable and unique  Common Mistakes to Avoid  ‚ùå Missing GSI keys: Always populate GSI1PK/GSI1SK and GSI2PK/GSI2SK ‚ùå Inconsistent patterns: Stick to ENTITY#ID format ‚ùå Wrong data types: Use strings for keys, appropriate types for values ‚ùå JSON syntax errors: Missing quotes, commas, or brackets  Important: If you get JSON syntax errors, check your quotation marks, commas, and brackets. The console will highlight syntax issues.\n\rCustomize Your Data Make It Personal Customize these values to make the workshop yours:\n User names and emails: Use your own information Product names: Create products you find interesting Addresses: Use your city/state Prices: Realistic values for your products  Add More Items Consider creating additional:\n More users (friends, family names) More products (different categories) Additional orders Multiple items per order  Ready for Querying Now that you have a complete e-commerce dataset with proper Single Table Design patterns, you\u0026rsquo;re ready to explore different query patterns. In the next section, we\u0026rsquo;ll learn how to efficiently retrieve this data using various query techniques.\nData Creation Complete: You\u0026rsquo;ve successfully implemented Single Table Design with proper entity relationships, composite keys, and GSI patterns!\n\r"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/2-single-table-design/2.4-query-patterns/",
	"title": "2.4 Query Patterns",
	"tags": [],
	"description": "",
	"content": "Query Patterns üîç Learn efficient query techniques using DynamoDB Console\nOverview Learn how to retrieve data efficiently using both table queries and Global Secondary Index (GSI) queries.\nQuery vs Scan  Query: Fast, efficient, uses primary keys ‚úÖ Scan: Slow, expensive, reads entire table ‚ùå  Important: Always use Query operations. Scan operations can exceed Free Tier limits.\n\rAccess Query Interface  Go to: Items tab in your DynamoDB table Click: \u0026ldquo;Query\u0026rdquo; button (not Scan) Select: Table query or Index query  Pattern 1: Get User Profile Objective: Get specific user information\nQuery Configuration:\n Partition key (PK): USER#user001 Sort key (SK): PROFILE  Result: Single item with user profile data\nPattern 2: Get User\u0026rsquo;s Orders Objective: Get all orders for a user\nQuery Configuration:\n Partition key (PK): USER#user001 Sort key condition: \u0026ldquo;begins_with\u0026rdquo; Sort key value: ORDER#  Result: User profile + all their orders\nPattern 3: Get Order Details Objective: Get complete order information\nQuery Configuration:\n Partition key (PK): ORDER#order001 Sort key: Leave empty (gets all items)  Result: Order details + all order items\nPattern 4: Products by Category (GSI) Objective: Find products in specific category\nSwitch to GSI Query:\n Click \u0026ldquo;Query (index)\u0026rdquo; Choose Index: GSI1  Query Configuration:\n GSI1 Partition key: CATEGORY#electronics GSI1 Sort key: Leave empty  Result: All electronics products\nPattern 5: Orders by Status (GSI) Objective: Find orders with specific status\nQuery Configuration:\n Choose Index: GSI2 GSI2 Partition key: STATUS#pending  Result: All pending orders\nQuery Performance Expected Performance:\n Single item: ~1-2ms, 1 RCU Multi-item: ~3-5ms, 2-5 RCU GSI queries: ~2-4ms, 1-3 RCU  Best Practices  Always use Query (never Scan) Design keys for queries first Use GSIs strategically for different access patterns Monitor performance and consumed capacity  Query Mastery: You can now efficiently retrieve data using Single Table Design patterns!\n\rNext Steps Ready for global scale! Next module covers Global Tables for multi-region deployment.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/3-global-tables-setup/3.1-global-tables-overview/",
	"title": "3.1 Global Tables Overview",
	"tags": [],
	"description": "",
	"content": "Global Tables Overview üåê Understanding DynamoDB Global Tables architecture and replication mechanisms\nWhat Are Global Tables? Global Tables enable you to create a multi-region, multi-master database that provides local read and write performance for globally distributed applications. Your CloudFormation deployment has already configured this for you.\nArchitecture Components Current Workshop Setup Your infrastructure already includes:\n   Component US-East-1 EU-West-1 Status     DynamoDB Table Primary Replica ‚úÖ Active   Table Name demo-ecommerce-freetier demo-ecommerce-freetier ‚úÖ Synced   DynamoDB Streams Enabled Enabled ‚úÖ Replicating   Replication Bi-directional Bi-directional ‚úÖ Healthy    Replication Process How Data Flows Between Regions    Step Action Details     Step 1 User writes to US-EAST-1     Item USER#john, SK: PROFILE    Local write Immediate success    Stream record Created   Step 2 DynamoDB Streams captures change     Stream record NEW_AND_OLD_IMAGES    Timestamp 2025-08-11T15:30:00.123Z    Event INSERT   Step 3 Cross-region replication     Source us-east-1 stream    Target eu-west-1 table    Latency 500ms - 2 seconds   Step 4 EU-WEST-1 receives update     Item appears USER#john, SK: PROFILE    Available for reads Immediately    Status Replicated ‚úÖ    Consistency Model Eventually Consistent Global Tables provides eventual consistency across regions:\n Immediate: Write succeeds immediately in the source region Propagation: Changes replicate to other regions within 0.5-2 seconds Convergence: All regions eventually have identical data Durability: Data is never lost during replication  Conflict Resolution When the same item is modified in multiple regions simultaneously:\nLast Writer Wins strategy:\n Compare timestamps of conflicting updates Keep the later timestamp (more recent change) Overwrite earlier changes in all regions Notify through CloudWatch metrics  Example conflict scenario:\nTime: 15:30:00 - US user updates: name = \u0026#34;John Smith\u0026#34; Time: 15:30:01 - EU user updates: name = \u0026#34;John Doe\u0026#34; Result: All regions will have name = \u0026#34;John Doe\u0026#34; (EU update wins due to later timestamp) Global Tables Benefits Performance Benefits  Local Latency: Sub-10ms response times in each region Global Scale: Serve users worldwide without performance penalty Load Distribution: Traffic distributed across regions  Availability Benefits  Regional Failover: Automatic failover if one region becomes unavailable Disaster Recovery: Built-in DR across geographic regions 99.999% Availability: Higher availability than single-region deployments  Operational Benefits  No Code Changes: Applications work with any region Automatic Scaling: Each region scales independently Unified Management: Single table view across all regions  Key Concepts to Remember Multi-Master Replication  Any region can accept writes All regions can serve reads No single point of failure  Stream-Based Replication  DynamoDB Streams power the replication Ordered delivery ensures consistency Retry logic handles temporary failures  Region Independence  Each region operates independently Network partitions don\u0026rsquo;t affect local operations Cross-region connectivity only needed for replication  Workshop Advantage: Your CloudFormation template has already configured all Global Tables components. You can focus on understanding and testing the functionality!\n\rLimitations to Understand Eventual Consistency Challenges  Temporary inconsistencies possible for 0.5-2 seconds Application design must handle eventual consistency Strong consistency only available within single region  Conflict Resolution Limitations  Last Writer Wins can overwrite changes No custom conflict resolution logic Application-level conflict handling may be needed  Cross-Region Dependencies  Network connectivity required for replication Regional outages can delay replication Cross-region latency affects replication speed  Real-World Use Cases Ideal for Global Tables    Use Case Why It Works Considerations     User Profiles Infrequent updates, read-heavy Handle profile conflicts   Product Catalogs Content distribution, global access Inventory sync challenges   Gaming Leaderboards Global competition, eventual consistency OK Score conflicts possible   IoT Sensor Data Time-series data, append-only High write volume    Challenging Scenarios  Financial transactions (require strong consistency) Inventory management (stock levels need accuracy) Real-time collaboration (immediate consistency needed)  Next Steps Now that you understand Global Tables architecture, let\u0026rsquo;s verify your multi-region setup and see replication in action through the AWS Console.\nReady to Explore: Your Global Tables are already configured and running. Time to see them in action!\n\r"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/3-global-tables-setup/3.2-verify-global-setup/",
	"title": "3.2 Verify Global Setup",
	"tags": [],
	"description": "",
	"content": "Verify Global Setup ‚úÖ Step-by-step verification of your Global Tables configuration through AWS Console\nOverview Your CloudFormation template has automatically configured Global Tables between US-East-1 and EU-West-1. Let\u0026rsquo;s verify everything is working correctly before we start testing replication.\nStep 1: Access Primary Region Navigate to US-East-1  Open AWS Console: Ensure you\u0026rsquo;re logged in Check Region: Top-right corner should show \u0026ldquo;N. Virginia\u0026rdquo; Switch if needed: Click region dropdown ‚Üí \u0026ldquo;US East (N. Virginia)\u0026rdquo;  Find Your DynamoDB Table  Services: Navigate to DynamoDB service Tables: Click \u0026ldquo;Tables\u0026rdquo; in left sidebar Locate: Find demo-ecommerce-freetier Status: Verify table shows \u0026ldquo;Active\u0026rdquo;  Step 2: Check Global Tables Configuration Access Global Tables Tab  Click: Table name demo-ecommerce-freetier Navigate: Click \u0026ldquo;Global tables\u0026rdquo; tab Review: Global Tables configuration  Verify Global Tables Status Expected Configuration:\n   Region Status Role Health     us-east-1 Active Primary ‚úÖ Healthy   eu-west-1 Active Replica ‚úÖ Healthy    Key indicators to verify:\n Replication Status: \u0026ldquo;Healthy\u0026rdquo; or \u0026ldquo;Active\u0026rdquo; Last Replication: Recent timestamp Pending Updates: Should be 0  Step 3: Verify Secondary Region Switch to EU-West-1  Region Selector: Click region dropdown (top-right) Select: \u0026ldquo;Europe (Ireland)\u0026rdquo; - eu-west-1 Wait: Allow console to switch regions  Check Replica Table  Navigate: DynamoDB ‚Üí Tables Find: Same table name demo-ecommerce-freetier Verify: Table exists and shows \u0026ldquo;Active\u0026rdquo; Check: Global tables tab shows replica status  Expected in EU-West-1:\n Table Name: demo-ecommerce-freetier (identical) Status: Active Role: Replica table Primary Region: us-east-1  Step 4: Compare Table Schemas Verify Schema Consistency Both regions should have identical table schema:\nPrimary Keys:\n Partition Key: PK (String) Sort Key: SK (String)  Global Secondary Indexes:\n GSI1: GSI1PK (String), GSI1SK (String) GSI2: GSI2PK (String), GSI2SK (String)  Settings:\n Read Capacity: 5 units (provisioned) Write Capacity: 5 units (provisioned) Point-in-time Recovery: Enabled DynamoDB Streams: Enabled  Step 5: Check Current Data Verify Existing Data Replication If you\u0026rsquo;ve completed Module 2, check that your existing data appears in both regions:\nSwitch to US-East-1:\n Go to: Items tab Count items: Note the number of items  Switch to EU-West-1:\n Go to: Items tab Compare count: Should match US region exactly  If item counts don\u0026rsquo;t match:\n Wait 1-2 minutes for replication Refresh the browser page Check Global Tables health status  Step 6: Verify Stream Configuration Check DynamoDB Streams In US-East-1:\n Table Overview: Go to table details Exports and streams: Click tab Stream details: Verify settings  Expected Stream Configuration:\n Stream Status: Enabled Stream view type: New and old images Stream ARN: Should be present Shard count: 1 or more active shards  Step 7: Health Check Dashboard Monitor Replication Health Access Monitoring:\n Metrics Tab: Click in table view Global Tables metrics: Look for replication metrics Key metrics:  Replication latency Pending replication count Failed replication events    Healthy Indicators:\n Replication Latency: \u0026lt; 2 seconds average Pending Count: 0 or very low Error Rate: 0%  Step 8: Network Connectivity Test Test Cross-Region Communication Simple connectivity verification:\n Create test item in US-East-1 Wait 30 seconds Check EU-West-1 for the item Delete test item from either region  Test Item Example:\n{ \u0026#34;PK\u0026#34;: \u0026#34;TEST#connectivity\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;VERIFICATION\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-08-11T15:00:00Z\u0026#34;, \u0026#34;test_purpose\u0026#34;: \u0026#34;global_tables_verification\u0026#34; } Troubleshooting Common Issues Issue: Table Not Found in EU-West-1 Possible Causes:\n Wrong region selected CloudFormation deployment incomplete Global Tables setup failed  Solutions:\n Double-check region in top-right corner Verify CloudFormation stack completed successfully Check IAM permissions for cross-region access  Issue: Replication Status Unhealthy Check These Items:\n Network connectivity between regions DynamoDB Streams enabled on source table IAM permissions for Global Tables service Table capacity not throttling  Issue: Item Counts Don\u0026rsquo;t Match Troubleshooting Steps:\n Wait longer (up to 2 minutes) Refresh browser page Check for errors in CloudWatch logs Verify no throttling in metrics  Verification Checklist Before proceeding to multi-region operations:\n Both regions accessible through AWS Console Table exists in both us-east-1 and eu-west-1 Global Tables status shows \u0026ldquo;Healthy\u0026rdquo; or \u0026ldquo;Active\u0026rdquo; Schema identical between regions DynamoDB Streams enabled Existing data replicated (if any) Test connectivity working Monitoring metrics available  Verification Complete: Your Global Tables setup is healthy and ready for multi-region operations!\n\rNext Steps With Global Tables verified and healthy, you\u0026rsquo;re ready to experience multi-region operations. In the next section, we\u0026rsquo;ll create data in one region and watch it automatically appear in another!\nPro Tip: Keep both region tabs open in your browser (US-East-1 and EU-West-1) to easily switch between them during exercises.\n\r"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/3-global-tables-setup/3.3-multi-region-operations/",
	"title": "3.3 Multi-Region Operations",
	"tags": [],
	"description": "",
	"content": "Multi-Region Operations üåç Hands-on practice with cross-region read/write operations and replication testing\nOverview Now that your Global Tables are verified, let\u0026rsquo;s experience multi-region operations firsthand. You\u0026rsquo;ll create data in one region, verify it replicates to another, and test conflict resolution scenarios.\nExercise 1: Write to Primary, Read from Replica Step 1: Create Global User in US-East-1 Ensure you\u0026rsquo;re in US-East-1:\n Check region: Top-right should show \u0026ldquo;N. Virginia\u0026rdquo; Navigate: DynamoDB ‚Üí Tables ‚Üí demo-ecommerce-freetier Go to: Items tab Click: \u0026ldquo;Create item\u0026rdquo;  User Creation Template Switch to JSON view and create:\n{ \u0026#34;PK\u0026#34;: \u0026#34;USER#global-user-[your-name]\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;PROFILE\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;USER#[your-name]@global.com\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;PROFILE\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;global-user-[your-name]\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;[Your Name] Global\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;[your-name]@global.com\u0026#34;, \u0026#34;region_created\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;created_timestamp\u0026#34;: \u0026#34;2025-08-11T15:30:00Z\u0026#34;, \u0026#34;test_type\u0026#34;: \u0026#34;global_replication\u0026#34;, \u0026#34;workshop_session\u0026#34;: \u0026#34;module3\u0026#34; } Important: Replace [your-name] with your actual name to make items unique.\nStep 2: Note Creation Time Record the details:\n Click \u0026ldquo;Create item\u0026rdquo; Note the time: Record when you clicked create Take screenshot: Of the created item  Step 3: Switch to EU-West-1 Change regions:\n Region selector: Click dropdown (top-right) Select: \u0026ldquo;Europe (Ireland)\u0026rdquo; Wait: For region switch to complete Navigate: DynamoDB ‚Üí Tables ‚Üí demo-ecommerce-freetier  Step 4: Query for Replicated Data Search for your user:\n Items tab: Navigate to items view Click: \u0026ldquo;Query\u0026rdquo; button Configure query:  Partition key (PK): USER#global-user-[your-name] Sort key (SK): PROFILE   Click: \u0026ldquo;Run\u0026rdquo;  Step 5: Verify Replication Expected results:\n If immediate: Item appears right away If delayed: Wait 30-60 seconds and try again Replication time: Note how long it took  Verify the data:\n All attributes: Should match exactly region_created: Should still show \u0026ldquo;us-east-1\u0026rdquo; Timestamps: Should be identical  Exercise 2: Write from Replica, Read from Primary Step 1: Create Product in EU-West-1 Stay in EU-West-1 and create a product:\n{ \u0026#34;PK\u0026#34;: \u0026#34;PRODUCT#eu-product-[unique-id]\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;DETAILS\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;CATEGORY#eu-electronics\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;PRODUCT#eu-product-[unique-id]\u0026#34;, \u0026#34;GSI2PK\u0026#34;: \u0026#34;PRICE#200-500\u0026#34;, \u0026#34;GSI2SK\u0026#34;: \u0026#34;PRODUCT#eu-product-[unique-id]\u0026#34;, \u0026#34;product_id\u0026#34;: \u0026#34;eu-product-[unique-id]\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;European Smartphone\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Created in EU region\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;eu-electronics\u0026#34;, \u0026#34;price\u0026#34;: 299, \u0026#34;stock\u0026#34;: 50, \u0026#34;region_created\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;created_timestamp\u0026#34;: \u0026#34;2025-08-11T15:35:00Z\u0026#34;, \u0026#34;test_type\u0026#34;: \u0026#34;reverse_replication\u0026#34; } Step 2: Switch Back to US-East-1 Return to primary region:\n Region selector: \u0026ldquo;US East (N. Virginia)\u0026rdquo; Navigate: DynamoDB ‚Üí Tables ‚Üí Items Query for product:  PK: PRODUCT#eu-product-[unique-id] SK: DETAILS    Step 3: Verify Reverse Replication Check the results:\n Product appears: In US region region_created: Still shows \u0026ldquo;eu-west-1\u0026rdquo; All data intact: Exact copy from EU  This demonstrates bi-directional replication - you can write to any region!\nExercise 3: Conflict Resolution Testing Step 1: Create Base Order In US-East-1, create an order:\n{ \u0026#34;PK\u0026#34;: \u0026#34;USER#global-user-[your-name]\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;ORDER#conflict-test\u0026#34;, \u0026#34;GSI1PK\u0026#34;: \u0026#34;ORDER#conflict-test\u0026#34;, \u0026#34;GSI1SK\u0026#34;: \u0026#34;DETAILS\u0026#34;, \u0026#34;GSI2PK\u0026#34;: \u0026#34;STATUS#pending\u0026#34;, \u0026#34;GSI2SK\u0026#34;: \u0026#34;ORDER#conflict-test\u0026#34;, \u0026#34;order_id\u0026#34;: \u0026#34;conflict-test\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;global-user-[your-name]\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;pending\u0026#34;, \u0026#34;total_amount\u0026#34;: 100, \u0026#34;last_updated_region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;conflict_test\u0026#34;: true } Wait 2 minutes for replication to complete.\nStep 2: Simultaneous Updates (Advanced) If working with a partner:\n Partner A: Update order in US-East-1 Partner B: Update same order in EU-West-1 Both execute: Within 10 seconds of each other  US Update (Partner A):\n{ \u0026#34;total_amount\u0026#34;: 150, \u0026#34;last_updated_region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;update_timestamp\u0026#34;: \u0026#34;2025-08-11T15:40:00Z\u0026#34; } EU Update (Partner B):\n{ \u0026#34;total_amount\u0026#34;: 200, \u0026#34;last_updated_region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;update_timestamp\u0026#34;: \u0026#34;2025-08-11T15:40:05Z\u0026#34; } Step 3: Observe Conflict Resolution After 2-3 minutes:\n Check both regions: Query the same order Compare results: Which update won? Understand why: Later timestamp wins  Expected outcome: EU update wins because timestamp 15:40:05 \u0026gt; 15:40:00\nExercise 4: Query Patterns Across Regions Step 1: Category Query in EU Test GSI queries work across regions:\n Stay in EU-West-1 Query Index: GSI1 GSI1PK: CATEGORY#eu-electronics Run query  Expected: Shows products created in EU region\nStep 2: Status Query in US Test cross-region status queries:\n Switch to US-East-1 Query Index: GSI2 GSI2PK: STATUS#pending Run query  Expected: Shows orders from both regions with pending status\nExercise 5: Replication Timing Analysis Step 1: Measure Replication Speed Create timestamped items:\n Record start time: Note exact time before creation Create item: In one region Switch regions: Immediately Query repeatedly: Until item appears Calculate delay: End time - start time  Test Item Template:\n{ \u0026#34;PK\u0026#34;: \u0026#34;TEST#timing-[timestamp]\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;REPLICATION\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;[exact-timestamp]\u0026#34;, \u0026#34;source_region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;test_purpose\u0026#34;: \u0026#34;timing_analysis\u0026#34; } Step 2: Document Results Record your findings:\n Fastest replication: ___ seconds Slowest replication: ___ seconds Average time: ___ seconds Consistency: Usually \u0026lt; 2 seconds  Real-World Scenarios Scenario 1: Global User Login Simulate global application:\n User logs in: US region Profile updated: Last login timestamp User travels: EU region App checks: Profile from EU Verify: Recent login time visible  Scenario 2: Inventory Management Product stock updates:\n Product sold: US region (-1 stock) Same product: EU region query Stock level: Eventually consistent Business logic: Handle temporary inconsistency  Scenario 3: Order Processing Multi-region order flow:\n Order created: EU region Payment processed: US region Status updated: EU region Fulfillment: Reads from nearest region  Performance Monitoring Check Replication Metrics During exercises:\n Monitor: CloudWatch metrics Watch: Replication latency Observe: Pending replication count Track: Error rates (should be 0)  Troubleshooting Guide Replication Not Working Common issues:\n Wrong region: Double-check region selection Typos in keys: Exact match required for queries Browser cache: Refresh page Wait longer: Up to 2 minutes possible  Queries Returning Empty Checklist:\n Correct PK/SK: Exact string match Region correct: Item exists in queried region GSI populated: GSI keys included in item Query type: Using Query, not Scan  Conflict Resolution Unexpected Understanding:\n Timestamp precision: Millisecond level Clock synchronization: AWS handles timing Application design: Plan for overwrites  Important: If you experience issues, check the Global Tables health status in the console and verify network connectivity.\n\rExercise Summary By completing these exercises, you\u0026rsquo;ve experienced:\n ‚úÖ Cross-region replication in both directions ‚úÖ Eventual consistency timing ‚úÖ Conflict resolution with Last Writer Wins ‚úÖ Query patterns working across regions ‚úÖ Real-world scenarios and timing analysis  Multi-Region Mastery: You now understand how Global Tables enables truly global applications with local performance!\n\rNext Steps With hands-on Global Tables experience complete, let\u0026rsquo;s monitor the replication performance and understand the metrics that help you operate global applications in production.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/4-streams-lambda-processing/4.1-stream-configuration/",
	"title": "4.1 Stream Configuration",
	"tags": [],
	"description": "",
	"content": "Enable DynamoDB Streams üîß Turn on change tracking for your DynamoDB table\nOverview DynamoDB Streams capture every change to your table items. This enables real-time processing with Lambda functions.\nStream View Types Choose what data to capture:\n NEW_AND_OLD_IMAGES: Complete before/after data (recommended for demo) NEW_IMAGE: Only updated data OLD_IMAGE: Only previous data KEYS_ONLY: Just the keys  Step-by-Step: Enable Streams Step 1: Open DynamoDB Console  AWS Console ‚Üí Search \u0026ldquo;DynamoDB\u0026rdquo; Tables ‚Üí Click your table demo-ecommerce-freetier Click \u0026ldquo;Exports and streams\u0026rdquo; tab  Step 2: Turn On Stream  Find \u0026ldquo;DynamoDB stream\u0026rdquo; section Click \u0026ldquo;Turn on\u0026rdquo; button Select \u0026ldquo;New and old images\u0026rdquo; Click \u0026ldquo;Turn on stream\u0026rdquo;  Step 3: Note Stream ARN Copy the Stream ARN - you\u0026rsquo;ll need it for Lambda setup:\narn:aws:dynamodb:us-east-1:123456789012:table/demo-ecommerce-freetier/stream/2025-08-13T10:00:00.000\rVerification ‚úÖ Stream status shows \u0026ldquo;Enabled\u0026rdquo;\n‚úÖ Stream ARN is displayed\n‚úÖ View type is \u0026ldquo;New and old images\u0026rdquo; 3. View type selection: Choose \u0026ldquo;New and old images\u0026rdquo; 4. Confirmation: Click \u0026ldquo;Turn on stream\u0026rdquo;\nStep 3: Verify Stream Configuration Check stream status:\n Stream details: Note the stream ARN appears Status: Should show \u0026ldquo;Active\u0026rdquo; View type: Confirms \u0026ldquo;New and old images\u0026rdquo; Creation time: Shows when stream was enabled  Exercise 2: Understanding Stream Settings Stream View Type Comparison Choose the right view type for your use case:\n   View Type Use Case Data Captured     KEYS_ONLY Audit logging PK, SK only   NEW_IMAGE Cache updates Item after change   OLD_IMAGE Change tracking Item before change   NEW_AND_OLD_IMAGES Full audit Both versions    Performance Considerations Stream Configuration Impact:\n Storage: NEW_AND_OLD_IMAGES uses most space Lambda payload: Larger payloads with full images Processing time: More data = longer processing Cost: Minimal additional cost for streams  Free Tier Note: DynamoDB Streams are included at no additional charge. Lambda processing stays within Free Tier limits.\n\rExercise 3: Test Stream Functionality Step 1: Create Test Item Generate a stream event:\n Items tab: Go back to \u0026ldquo;Items\u0026rdquo; tab Create item: Click \u0026ldquo;Create item\u0026rdquo; Add test data:  { \u0026#34;PK\u0026#34;: \u0026#34;STREAM#test-item\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;EVENT#001\u0026#34;, \u0026#34;event_type\u0026#34;: \u0026#34;stream_test\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Testing DynamoDB Stream functionality\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T16:00:00Z\u0026#34;, \u0026#34;test_purpose\u0026#34;: \u0026#34;verify_stream_capture\u0026#34; } Create: Click \u0026ldquo;Create item\u0026rdquo;  Step 2: Monitor Stream Activity Check stream metrics:\n CloudWatch: Open CloudWatch console in new tab Metrics: Navigate to Metrics DynamoDB: Click \u0026ldquo;DynamoDB\u0026rdquo; namespace Stream metrics: Look for stream-related metrics IncomingRecords: Should show 1 new record  Step 3: Understand Stream Records Stream record structure (for reference):\n{ \u0026#34;Records\u0026#34;: [ { \u0026#34;eventID\u0026#34;: \u0026#34;12345...\u0026#34;, \u0026#34;eventName\u0026#34;: \u0026#34;INSERT\u0026#34;, \u0026#34;eventVersion\u0026#34;: \u0026#34;1.1\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;aws:dynamodb\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;dynamodb\u0026#34;: { \u0026#34;ApproximateCreationDateTime\u0026#34;: 1642857600, \u0026#34;Keys\u0026#34;: { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;STREAM#test-item\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;EVENT#001\u0026#34;} }, \u0026#34;NewImage\u0026#34;: { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;STREAM#test-item\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;EVENT#001\u0026#34;}, \u0026#34;event_type\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;stream_test\u0026#34;}, \u0026#34;description\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Testing DynamoDB Stream functionality\u0026#34;}, \u0026#34;created_at\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;2025-08-11T16:00:00Z\u0026#34;}, \u0026#34;test_purpose\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;verify_stream_capture\u0026#34;} }, \u0026#34;SequenceNumber\u0026#34;: \u0026#34;123456789\u0026#34;, \u0026#34;SizeBytes\u0026#34;: 245, \u0026#34;StreamViewType\u0026#34;: \u0026#34;NEW_AND_OLD_IMAGES\u0026#34; } } ] } Key components:\n eventName: INSERT (since this is a new item) Keys: Primary key of the changed item NewImage: Complete item data after creation OldImage: Would be empty for INSERT events  Exercise 4: Stream Configuration Best Practices Optimal Configuration for Workshop Recommended settings:\n ‚úÖ View Type: NEW_AND_OLD_IMAGES (comprehensive audit trail) ‚úÖ Retention: 24 hours (default, sufficient for processing) ‚úÖ Shards: Auto-managed by AWS ‚úÖ Processing: Lambda with appropriate batch size  Security Considerations Access control:\n IAM permissions: Lambda needs stream read permissions Encryption: Streams inherit table encryption settings VPC: Streams work within your VPC configuration Monitoring: CloudTrail logs stream access  Cost Optimization Stream cost factors:\n Read requests: No additional charge for stream writes Lambda invocations: Count toward Free Tier Data transfer: Minimal for in-region processing Storage: Stream records retained for 24 hours only  Exercise 5: Advanced Stream Configuration Multiple Consumer Pattern When you need multiple processors:\n Single stream: One DynamoDB stream per table Multiple Lambdas: Each can process the same stream Kinesis Data Streams: For more complex routing Event filtering: Lambda-level filtering  Cross-Region Considerations Global Tables + Streams:\n Each region: Has its own stream Replication events: Generate stream records Filtering: Distinguish app writes from replication Processing: Handle regional differences  Troubleshooting Common Issues Stream Not Appearing Check these items:\n Permissions: Ensure you have DynamoDB full access Region: Verify you\u0026rsquo;re in the correct AWS region Table status: Table must be ACTIVE to enable streams Refresh: Browser refresh may be needed  Stream Configuration Failed Possible causes:\n Table updating: Wait for table to be ACTIVE Permissions: Need dynamodb:EnableStream permission Rate limits: Wait and retry if rate limited Billing: Ensure account is in good standing  Stream Records Missing Debugging steps:\n Stream status: Confirm stream is ACTIVE Write operations: Ensure items are actually changing Time delay: Allow 1-2 minutes for propagation Metrics: Check CloudWatch for IncomingRecords  Configuration Summary By completing this exercise, you have:\n ‚úÖ Enabled DynamoDB Streams on your table ‚úÖ Configured view type for comprehensive change capture ‚úÖ Tested stream functionality with sample data ‚úÖ Understood stream record structure and components ‚úÖ Applied best practices for optimal configuration  Stream Ready: Your DynamoDB table now captures every change and is ready for Lambda processing!\n\rNext Steps With streams configured, you\u0026rsquo;re ready to create Lambda functions that will process these events in real-time. In the next section, we\u0026rsquo;ll build and deploy a Lambda function optimized for DynamoDB stream processing.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/4-streams-lambda-processing/4.2-lambda-function-setup/",
	"title": "4.2 Lambda Function Setup",
	"tags": [],
	"description": "",
	"content": "Create Stream Processing Lambda ‚öôÔ∏è Build a Lambda function to process DynamoDB stream events in real-time\nOverview AWS Lambda provides serverless compute to process DynamoDB stream events. Your function will automatically trigger when items change in your table, enabling real-time processing patterns.\nFunction Requirements Free Tier Optimized Configuration:\n Runtime: Python 3.9 (reliable and well-supported) Memory: 128 MB (minimum for Free Tier) Timeout: 30 seconds (sufficient for stream processing) Concurrent executions: 10 (Free Tier safe)  Exercise 1: Create Lambda Function Step 1: Access Lambda Console Navigate to Lambda service:\n AWS Console: Search \u0026ldquo;Lambda\u0026rdquo; Functions: Click \u0026ldquo;Functions\u0026rdquo; in left sidebar Create function: Click \u0026ldquo;Create function\u0026rdquo; button Author from scratch: Select this option  Step 2: Configure Basic Settings Function configuration:\n Function name: demo-dynamodb-stream-processor Runtime: Select \u0026ldquo;Python 3.9\u0026rdquo; Architecture: Leave as \u0026ldquo;x86_64\u0026rdquo; Permissions: \u0026ldquo;Create a new role with basic Lambda permissions\u0026rdquo; Create function: Click to proceed  Step 3: Configure Function Settings Optimize for Free Tier:\n Configuration tab: Click after function creation General configuration: Click \u0026ldquo;Edit\u0026rdquo; Memory: Set to 128 MB Timeout: Set to 30 seconds Save: Click to apply changes  Exercise 2: Add Stream Processing Code Step 1: Replace Function Code Navigate to code editor:\n Code tab: Click to open code editor lambda_function.py: Replace existing code with:  import json import boto3 import logging from datetime import datetime # Configure logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34; Process DynamoDB Stream events Optimized for AWS Free Tier \u0026#34;\u0026#34;\u0026#34; try: processed_records = 0 # Process each record in the batch for record in event[\u0026#39;Records\u0026#39;]: event_name = record[\u0026#39;eventName\u0026#39;] # Process INSERT, MODIFY, REMOVE events if event_name in [\u0026#39;INSERT\u0026#39;, \u0026#39;MODIFY\u0026#39;, \u0026#39;REMOVE\u0026#39;]: process_stream_record(record) processed_records += 1 # Return success response return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;message\u0026#39;: f\u0026#39;Successfully processed {processed_records}records\u0026#39;, \u0026#39;timestamp\u0026#39;: datetime.utcnow().isoformat(), \u0026#39;processed_count\u0026#39;: processed_records }) } except Exception as e: logger.error(f\u0026#34;Error processing stream records: {str(e)}\u0026#34;) # Re-raise for Lambda retry logic raise e def process_stream_record(record): \u0026#34;\u0026#34;\u0026#34; Process individual stream record Add your business logic here \u0026#34;\u0026#34;\u0026#34; event_name = record[\u0026#39;eventName\u0026#39;] # Extract key information if \u0026#39;dynamodb\u0026#39; in record: keys = record[\u0026#39;dynamodb\u0026#39;].get(\u0026#39;Keys\u0026#39;, {}) pk = keys.get(\u0026#39;PK\u0026#39;, {}).get(\u0026#39;S\u0026#39;, \u0026#39;\u0026#39;) sk = keys.get(\u0026#39;SK\u0026#39;, {}).get(\u0026#39;S\u0026#39;, \u0026#39;\u0026#39;) logger.info(f\u0026#34;Processing {event_name}for item: {pk}#{sk}\u0026#34;) # Handle different event types if event_name == \u0026#39;INSERT\u0026#39;: handle_insert_event(record) elif event_name == \u0026#39;MODIFY\u0026#39;: handle_modify_event(record) elif event_name == \u0026#39;REMOVE\u0026#39;: handle_remove_event(record) def handle_insert_event(record): \u0026#34;\u0026#34;\u0026#34; Handle new item creation \u0026#34;\u0026#34;\u0026#34; logger.info(\u0026#34;Processing INSERT event\u0026#34;) # Get new item data new_image = record[\u0026#39;dynamodb\u0026#39;].get(\u0026#39;NewImage\u0026#39;, {}) # Example: Send notification for new user if \u0026#39;USER#\u0026#39; in str(new_image.get(\u0026#39;PK\u0026#39;, {})): logger.info(\u0026#34;New user created - could send welcome email\u0026#34;) # Example: Update inventory for new product elif \u0026#39;PRODUCT#\u0026#39; in str(new_image.get(\u0026#39;PK\u0026#39;, {})): logger.info(\u0026#34;New product created - could update search index\u0026#34;) # Example: Process new order elif \u0026#39;ORDER#\u0026#39; in str(new_image.get(\u0026#39;SK\u0026#39;, {})): logger.info(\u0026#34;New order created - could trigger fulfillment\u0026#34;) def handle_modify_event(record): \u0026#34;\u0026#34;\u0026#34; Handle item updates \u0026#34;\u0026#34;\u0026#34; logger.info(\u0026#34;Processing MODIFY event\u0026#34;) # Get before and after images old_image = record[\u0026#39;dynamodb\u0026#39;].get(\u0026#39;OldImage\u0026#39;, {}) new_image = record[\u0026#39;dynamodb\u0026#39;].get(\u0026#39;NewImage\u0026#39;, {}) # Example: Check for status changes old_status = old_image.get(\u0026#39;status\u0026#39;, {}).get(\u0026#39;S\u0026#39;, \u0026#39;\u0026#39;) new_status = new_image.get(\u0026#39;status\u0026#39;, {}).get(\u0026#39;S\u0026#39;, \u0026#39;\u0026#39;) if old_status != new_status: logger.info(f\u0026#34;Status changed from {old_status}to {new_status}\u0026#34;) # Could trigger notifications, cache updates, etc. # Example: Price change detection old_price = old_image.get(\u0026#39;price\u0026#39;, {}).get(\u0026#39;N\u0026#39;, \u0026#39;0\u0026#39;) new_price = new_image.get(\u0026#39;price\u0026#39;, {}).get(\u0026#39;N\u0026#39;, \u0026#39;0\u0026#39;) if old_price != new_price: logger.info(f\u0026#34;Price changed from {old_price}to {new_price}\u0026#34;) # Could invalidate cache, update recommendations, etc. def handle_remove_event(record): \u0026#34;\u0026#34;\u0026#34; Handle item deletion \u0026#34;\u0026#34;\u0026#34; logger.info(\u0026#34;Processing REMOVE event\u0026#34;) # Get deleted item data old_image = record[\u0026#39;dynamodb\u0026#39;].get(\u0026#39;OldImage\u0026#39;, {}) # Example: Cleanup related data if \u0026#39;USER#\u0026#39; in str(old_image.get(\u0026#39;PK\u0026#39;, {})): logger.info(\u0026#34;User deleted - could cleanup user data\u0026#34;) # Example: Remove from search index elif \u0026#39;PRODUCT#\u0026#39; in str(old_image.get(\u0026#39;PK\u0026#39;, {})): logger.info(\u0026#34;Product deleted - could remove from search\u0026#34;) Deploy: Click \u0026ldquo;Deploy\u0026rdquo; to save the code  Step 2: Test Function Syntax Validate the code:\n Test tab: Click \u0026ldquo;Test\u0026rdquo; tab Create test event: Click \u0026ldquo;Create new event\u0026rdquo; Event template: Select \u0026ldquo;DynamoDB Update\u0026rdquo; template Event name: test-stream-event Test: Click \u0026ldquo;Test\u0026rdquo; to validate syntax  Exercise 3: Configure Event Source Mapping Step 1: Add DynamoDB Trigger Connect Lambda to DynamoDB Stream:\n Function overview: In Lambda console Add trigger: Click \u0026ldquo;Add trigger\u0026rdquo; button Trigger configuration:  Source: Select \u0026ldquo;DynamoDB\u0026rdquo; DynamoDB table: Choose demo-ecommerce-freetier Batch size: Set to 10 (Free Tier optimized) Starting position: Select \u0026ldquo;Trim horizon\u0026rdquo;   Add: Click to create trigger  Step 2: Verify Event Source Mapping Check trigger configuration:\n Function overview: Should show DynamoDB trigger Configuration: Verify settings:  Batch size: 10 records Starting position: Trim horizon Status: Enabled State: Creating ‚Üí Enabled    Step 3: Configure IAM Permissions Update Lambda execution role:\n Configuration tab: Click \u0026ldquo;Permissions\u0026rdquo; Execution role: Click role name link IAM console: Opens in new tab Attach policies: Add AWSLambdaDynamoDBExecutionRole Save: Return to Lambda console  Exercise 4: Test Stream Processing Step 1: Create Test Item Generate stream event:\n DynamoDB console: Open in new tab Items tab: Navigate to your table Create item: Add test data:  { \u0026#34;PK\u0026#34;: \u0026#34;LAMBDA#test-processing\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;EVENT#001\u0026#34;, \u0026#34;event_type\u0026#34;: \u0026#34;lambda_test\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Testing Lambda stream processing\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2025-08-11T16:30:00Z\u0026#34;, \u0026#34;test_purpose\u0026#34;: \u0026#34;verify_lambda_trigger\u0026#34; } Create: Save the item  Step 2: Monitor Lambda Execution Check function invocation:\n Lambda console: Return to your function Monitor tab: Click to view metrics Invocations: Should show 1 new invocation Duration: Typically \u0026lt; 1 second Errors: Should be 0  Step 3: Check Processing Logs View detailed logs:\n CloudWatch logs: Click \u0026ldquo;View CloudWatch logs\u0026rdquo; Log stream: Click latest log stream Log entries: Look for:  START RequestId: [uuid] Processing INSERT for item: LAMBDA#test-processing#EVENT#001 Processing INSERT event Successfully processed 1 records END RequestId: [uuid]    Exercise 5: Advanced Configuration Error Handling Configuration Configure retry and error handling:\n Event source mapping: Edit your DynamoDB trigger Additional settings:  Retry attempts: 3 (default) Maximum record age: 3600 seconds Split batch on error: Enable Dead letter queue: Configure SNS/SQS (optional)    Performance Optimization Free Tier optimization settings:\n Parallelization factor: 1 (avoid excess concurrency) Batch size: 10 records (balance latency vs cost) Reserved concurrency: 10 (control costs) Provisioned concurrency: 0 (not needed for streams)  Monitoring and Alerting Set up basic monitoring:\n CloudWatch Alarms: Create for:  Function errors \u0026gt; 0 Function duration \u0026gt; 20 seconds Iterator age \u0026gt; 30 seconds   Notifications: SNS topic for alerts Dashboard: Add metrics to CloudWatch dashboard  Function Testing Patterns Test Different Event Types Comprehensive testing:\n INSERT: Create new items MODIFY: Update existing items REMOVE: Delete items Batch: Multiple rapid changes  Validation Checklist Verify your setup:\n ‚úÖ Lambda function created with correct runtime ‚úÖ Stream trigger configured with proper permissions ‚úÖ Code deployed and syntax validated ‚úÖ Test successful with sample data ‚úÖ Logs showing processing details ‚úÖ Metrics indicating healthy execution  Troubleshooting Common Issues Lambda Not Triggering Check these items:\n Stream enabled: DynamoDB stream is active Permissions: Lambda has stream read permissions Event source mapping: Trigger is enabled Function state: Lambda is active (not failed)  Processing Errors Debug steps:\n CloudWatch logs: Check for error messages Timeout issues: Increase timeout if needed Memory errors: Monitor memory usage Permissions: Verify all required permissions  Performance Issues Optimization tips:\n Batch size: Adjust based on processing time Memory allocation: Right-size for your workload Cold starts: Consider provisioned concurrency if needed Error handling: Implement proper retry logic  Lambda Ready: Your function is now processing DynamoDB stream events in real-time!\n\rNext Steps With your Lambda function processing stream events, you\u0026rsquo;re ready to practice with real data changes and explore different event-driven patterns. The next section covers hands-on stream processing exercises.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/5-monitoring-optimization/5.1-cloudwatch-dashboards/",
	"title": "5.1 CloudWatch Basic Monitoring",
	"tags": [],
	"description": "",
	"content": "CloudWatch Basic Monitoring üìä View basic DynamoDB metrics in CloudWatch\nOverview CloudWatch automatically collects basic metrics from DynamoDB. We\u0026rsquo;ll explore how to view these metrics without creating complex dashboards.\nView DynamoDB Metrics Step 1: Access CloudWatch Metrics  AWS Console: Search \u0026ldquo;CloudWatch\u0026rdquo; Metrics: Click \u0026ldquo;Metrics\u0026rdquo; in left sidebar AWS/DynamoDB: Click on this namespace Table Metrics: Browse available metrics  Step 2: Check Key Metrics Monitor basic usage:\n ConsumedReadCapacityUnits: Check read usage ConsumedWriteCapacityUnits: Check write usage ItemCount: Number of items in table TableSizeBytes: Storage usage  Step 3: View Metric Details Click on any metric to see details:\n Select your table: demo-ecommerce-freetier View graph: Shows usage over time Check values: Ensure staying within Free Tier  Key Metrics to Check    Metric Purpose Free Tier Limit     ConsumedReadCapacityUnits Read usage 25 RCU/month   ConsumedWriteCapacityUnits Write usage 25 WCU/month   ItemCount Number of items No limit   TableSizeBytes Storage used 25 GB    Free Tier: All basic CloudWatch metrics for DynamoDB are free. No dashboard creation needed.\n\rSimple Monitoring Tips  Check metrics daily: Ensure staying within Free Tier Look for spikes: Unusual usage patterns Monitor storage: Track table size growth No alerts needed: Visual checking is sufficient for workshop  Basic Monitoring: You can now view essential DynamoDB metrics in CloudWatch!\n\rNext Steps Basic metric viewing is sufficient for this workshop. Move to the next module when ready.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/5-monitoring-optimization/5.2-cost-analysis-optimization/",
	"title": "5.2 Cost Analysis &amp; Optimization",
	"tags": [],
	"description": "",
	"content": "Cost Analysis \u0026amp; Free Tier Monitoring üí∞ Monitor AWS Free Tier usage to avoid unexpected charges\nOverview Learn to track your DynamoDB costs and stay within Free Tier limits during the workshop.\nFree Tier Limits    Service Free Tier Limit Workshop Usage Status     DynamoDB Read 25 RCU/month ~5-10 RCU ‚úÖ Safe   DynamoDB Write 25 WCU/month ~5-10 WCU ‚úÖ Safe   DynamoDB Storage 25 GB \u0026lt;1 GB ‚úÖ Safe   Lambda Requests 1M/month \u0026lt;1,000 ‚úÖ Safe   CloudWatch Metrics 10 custom 5-8 used ‚úÖ Safe    Exercise 1: Check Current Costs Step 1: Access Billing Dashboard  AWS Console: Click account name (top-right) Billing and Cost Management: Select from dropdown Cost Explorer: Click \u0026ldquo;Cost Explorer\u0026rdquo; in left sidebar Expected result: $0.00 for all services  Step 2: View Free Tier Usage  Billing console: Click \u0026ldquo;Free Tier\u0026rdquo; tab Check usage:  DynamoDB: Should show low usage percentages Lambda: Minimal invocations CloudWatch: Basic metrics usage    Exercise 2: Set Up Billing Alerts Step 1: Enable Billing Alerts  Billing preferences: Navigate to preferences Billing alerts: Enable \u0026ldquo;Receive Free Tier Usage Alerts\u0026rdquo; Email: Confirm notification email Thresholds: Set alerts at 80% of Free Tier limits  Step 2: Create Cost Budget  AWS Budgets: Navigate to Budgets service Create budget:  Budget type: Cost budget Amount: $1.00 (safety buffer) Period: Monthly Alert at: $0.80 (80% threshold)    Important: This workshop is designed to stay within Free Tier. Any charges indicate unexpected usage.\n\rCost Optimization Tips Keep Costs at Zero  Monitor usage: Check Free Tier dashboard weekly Clean up resources: Delete resources when workshop complete Avoid over-provisioning: Stick to workshop configurations Set alerts: Get notified before any charges  Workshop Resource Cleanup When finished with workshop:\n Delete DynamoDB table: Removes storage costs Delete Lambda functions: Removes compute costs Delete CloudWatch dashboards: Removes monitoring costs Remove IAM roles: Clean up permissions  Cost Control: Following workshop instructions keeps you within Free Tier limits.\n\rTroubleshooting Costs If You See Charges  Check region: Ensure using correct AWS region Review resources: Look for unexpected resource creation Contact support: AWS Free Tier support available Stop resources: Immediately stop any billable resources  Common Cost Issues  Wrong region: Resources in non-Free Tier regions Over-provisioning: Capacity above Free Tier limits Forgotten resources: Resources left running after workshop Data transfer: Cross-region data movement costs  Next Steps With cost monitoring in place, you can continue the workshop with confidence that you\u0026rsquo;ll stay within Free Tier limits.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/6-advanced-patterns/6.1-batch-operations/",
	"title": "6.1 Batch Operations",
	"tags": [],
	"description": "",
	"content": "Batch Operations ‚ö° Process multiple items efficiently with batch operations\nOverview Batch operations allow you to process multiple items in a single API call, reducing latency and improving performance.\nKey Benefits  BatchWriteItem: Insert or delete up to 25 items at once BatchGetItem: Retrieve up to 100 items at once Fewer API calls: Better performance and efficiency Lower latency: Bulk processing reduces round trips  Exercise 1: Simple Batch Write Step 1: Create Batch Product Data Use AWS CloudShell for batch operations:\n Open CloudShell: From AWS Console Create batch file: Generate JSON for multiple products  cat \u0026gt; batch-products.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; { \u0026#34;demo-ecommerce-freetier\u0026#34;: [ { \u0026#34;PutRequest\u0026#34;: { \u0026#34;Item\u0026#34;: { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#gaming-laptop\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;DETAILS\u0026#34;}, \u0026#34;GSI1PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;CATEGORY#electronics\u0026#34;}, \u0026#34;GSI1SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#gaming-laptop\u0026#34;}, \u0026#34;name\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Gaming Laptop Pro\u0026#34;}, \u0026#34;price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;1299\u0026#34;}, \u0026#34;stock\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;15\u0026#34;}, \u0026#34;category\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;electronics\u0026#34;} } } }, { \u0026#34;PutRequest\u0026#34;: { \u0026#34;Item\u0026#34;: { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#wireless-mouse\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;DETAILS\u0026#34;}, \u0026#34;GSI1PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;CATEGORY#electronics\u0026#34;}, \u0026#34;GSI1SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#wireless-mouse\u0026#34;}, \u0026#34;name\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Wireless Gaming Mouse\u0026#34;}, \u0026#34;price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;79\u0026#34;}, \u0026#34;stock\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;50\u0026#34;}, \u0026#34;category\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;electronics\u0026#34;} } } }, { \u0026#34;PutRequest\u0026#34;: { \u0026#34;Item\u0026#34;: { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#rgb-keyboard\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;DETAILS\u0026#34;}, \u0026#34;GSI1PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;CATEGORY#electronics\u0026#34;}, \u0026#34;GSI1SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#rgb-keyboard\u0026#34;}, \u0026#34;name\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;RGB Mechanical Keyboard\u0026#34;}, \u0026#34;price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;159\u0026#34;}, \u0026#34;stock\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;25\u0026#34;}, \u0026#34;category\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;electronics\u0026#34;} } } } ] } EOF Step 2: Execute Batch Write Perform batch write operation:\naws dynamodb batch-write-item --request-items file://batch-products.json Expected result: All 3 items created with one API call instead of 3 separate calls.\nStep 3: Verify Results Check DynamoDB Console:\n Navigate to your table items Look for the 3 new products:  PRODUCT#gaming-laptop PRODUCT#wireless-mouse PRODUCT#rgb-keyboard    Exercise 2: Batch Read Operations Step 1: Batch Get Items Retrieve multiple items at once:\ncat \u0026gt; batch-get.json \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; { \u0026#34;demo-ecommerce-freetier\u0026#34;: { \u0026#34;Keys\u0026#34;: [ { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#gaming-laptop\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;DETAILS\u0026#34;} }, { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#wireless-mouse\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;DETAILS\u0026#34;} }, { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#rgb-keyboard\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;DETAILS\u0026#34;} } ] } } EOF Step 2: Execute Batch Get aws dynamodb batch-get-item --request-items file://batch-get.json Performance comparison:\n Batch operation: 1 API call for 3 items Individual operations: 3 API calls for 3 items Result: 3x fewer API calls = better performance  Batch Operation Benefits Efficiency Gains    Operation Type Individual Calls Batch Calls Efficiency     Write 25 items 25 API calls 1 API call 25x faster   Read 100 items 100 API calls 1 API call 100x faster   Mixed operations Multiple calls 1 API call Much faster    Free Tier Benefits  Same RCU/WCU usage: Capacity consumption unchanged Fewer API calls: Better throughput within limits Reduced latency: Faster application response Efficient processing: More work done per request  Best Practices Batch Limits  BatchWriteItem: Maximum 25 items per request BatchGetItem: Maximum 100 items per request Item size: Each item still counts toward size limits Error handling: Some items may fail while others succeed  When to Use Batching Good for batching:\n Multiple related items to process Bulk data imports/exports Initialization or cleanup operations  Not ideal for batching:\n Single item operations Items requiring individual error handling Real-time user interactions  Batch Operations Mastery: You can now process multiple items efficiently, reducing API calls and improving application performance!\n\rNext Steps Continue to learn more advanced DynamoDB patterns or proceed to the next workshop module.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/6-advanced-patterns/6.2-conditional-updates/",
	"title": "6.2 Conditional Updates",
	"tags": [],
	"description": "",
	"content": "Conditional Updates üõ°Ô∏è Prevent race conditions with conditional updates\nOverview Conditional updates ensure data integrity by only updating items when specific conditions are met. This prevents race conditions in multi-user applications.\nThe Problem: Race Conditions Without conditions (dangerous):\nUser A reads: stock = 1 User B reads: stock = 1 User A updates: stock = 0 ‚úÖ User B updates: stock = 0 ‚ùå (Should fail!) Result: Oversold! With conditions (safe):\nUser A: stock = 0 (condition: stock \u0026gt;= 1) ‚úÖ User B: fails (condition: stock \u0026gt;= 1) ‚ùå Result: Only first succeeds ‚úÖ Exercise 1: Basic Conditional Updates Step 1: Create Test Product Create a product for testing:\naws dynamodb put-item \\  --table-name demo-ecommerce-freetier \\  --item \u0026#39;{ \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PRODUCT#conditional-test\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;DETAILS\u0026#34;}, \u0026#34;name\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Test Product\u0026#34;}, \u0026#34;price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;100\u0026#34;}, \u0026#34;stock\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;5\u0026#34;} }\u0026#39; Step 2: Safe Price Update Update price with condition:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET price = :new_price\u0026#34; \\  --condition-expression \u0026#34;price = :current_price\u0026#34; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:new_price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;90\u0026#34;}, \u0026#34;:current_price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;100\u0026#34;} }\u0026#39; Step 3: Failed Conditional Update Try update with wrong condition:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET price = :new_price\u0026#34; \\  --condition-expression \u0026#34;price = :wrong_price\u0026#34; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:new_price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;80\u0026#34;}, \u0026#34;:wrong_price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;100\u0026#34;} }\u0026#39; Result: ConditionalCheckFailedException error\nExercise 2: Prevent Overselling Step 1: Safe Stock Decrement Buy 2 items safely:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET stock = stock - :quantity\u0026#34; \\  --condition-expression \u0026#34;stock \u0026gt;= :quantity\u0026#34; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:quantity\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;2\u0026#34;} }\u0026#39; Step 2: Prevent Overselling Try to buy more than available:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET stock = stock - :quantity\u0026#34; \\  --condition-expression \u0026#34;stock \u0026gt;= :quantity\u0026#34; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:quantity\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;5\u0026#34;} }\u0026#39; Result: Fails because only 3 items in stock\nExercise 3: Version Control Step 1: Add Version to Product Update product with version number:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET version = :version\u0026#34; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:version\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;1\u0026#34;} }\u0026#39; Step 2: Version-Based Update Update with version check:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET price = :new_price, version = version + :inc\u0026#34; \\  --condition-expression \u0026#34;version = :expected_version\u0026#34; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:new_price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;85\u0026#34;}, \u0026#34;:inc\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;1\u0026#34;}, \u0026#34;:expected_version\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;1\u0026#34;} }\u0026#39; Step 3: Version Conflict Try update with old version:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET price = :new_price, version = version + :inc\u0026#34; \\  --condition-expression \u0026#34;version = :old_version\u0026#34; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:new_price\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;75\u0026#34;}, \u0026#34;:inc\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;1\u0026#34;}, \u0026#34;:old_version\u0026#34;: {\u0026#34;N\u0026#34;: \u0026#34;1\u0026#34;} }\u0026#39; Result: Fails because version is now 2, not 1\nExercise 4: Prevent Duplicates Step 1: Create Unique User Create user only if doesn\u0026rsquo;t exist:\naws dynamodb put-item \\  --table-name demo-ecommerce-freetier \\  --item \u0026#39;{ \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;USER#unique-user\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PROFILE\u0026#34;}, \u0026#34;email\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;user@example.com\u0026#34;} }\u0026#39; \\  --condition-expression \u0026#34;attribute_not_exists(PK)\u0026#34; Step 2: Try Duplicate Try to create same user again:\naws dynamodb put-item \\  --table-name demo-ecommerce-freetier \\  --item \u0026#39;{ \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;USER#unique-user\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;PROFILE\u0026#34;}, \u0026#34;email\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;different@example.com\u0026#34;} }\u0026#39; \\  --condition-expression \u0026#34;attribute_not_exists(PK)\u0026#34; Result: Fails - prevents duplicate users\nStep 3: Complex Conditions Update with multiple conditions:\naws dynamodb update-item \\  --table-name demo-ecommerce-freetier \\  --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PRODUCT#conditional-test\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;DETAILS\u0026#34;}}\u0026#39; \\  --update-expression \u0026#34;SET featured = :featured\u0026#34; \\  --condition-expression \u0026#34;contains(#n, :keyword)\u0026#34; \\  --expression-attribute-names \u0026#39;{\u0026#34;#n\u0026#34;: \u0026#34;name\u0026#34;}\u0026#39; \\  --expression-attribute-values \u0026#39;{ \u0026#34;:featured\u0026#34;: {\u0026#34;BOOL\u0026#34;: true}, \u0026#34;:keyword\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Test\u0026#34;} }\u0026#39; Monitoring Conditional Updates Check CloudWatch metrics:\n ConditionalCheckFailedException: Failed condition rate SuccessfulRequestLatency: Update performance ThrottledRequests: Capacity issues  Screenshot Location: Add screenshot of CloudWatch showing conditional update metrics\nKey Benefits  Prevents race conditions: Multiple users can\u0026rsquo;t oversell inventory Data integrity: Ensures business rules are enforced Version control: Prevents overwriting concurrent changes Duplicate prevention: Unique constraints without database locks  Conditional Updates Mastery: You can now safely handle concurrent access and prevent data corruption!\n\rNext Steps You\u0026rsquo;ve learned essential conditional update patterns for production applications.\n"
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://crimsondd.github.io/DynamoDB-Advanced-Patterns-and-Global-Tables-Streams/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]